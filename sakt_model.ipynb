{"cells":[{"metadata":{},"cell_type":"markdown","source":"Slightly re-structured version of this kernel: https://www.kaggle.com/manikanthr5/riiid-sakt-model-inference-public\n\nI have used it to improve the score to 0.775"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv\n/kaggle/input/riiid-test-answer-prediction/example_test.csv\n/kaggle/input/riiid-test-answer-prediction/questions.csv\n/kaggle/input/riiid-test-answer-prediction/train.csv\n/kaggle/input/riiid-test-answer-prediction/lectures.csv\n/kaggle/input/riiid-test-answer-prediction/riiideducation/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/riiid-test-answer-prediction/riiideducation/__init__.py\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport random\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.utils.rnn as rnn_utils\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport datatable as dt","execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/input')\nassert path.exists()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndata_types_dict = {\n    'content_type_id': 'bool',\n    'timestamp': 'int64',\n    'user_id': 'int32', \n    'content_id': 'int16', \n    'answered_correctly': 'int8', \n    'prior_question_elapsed_time': 'float32', \n    'prior_question_had_explanation': 'bool'\n}\ntarget = 'answered_correctly'\ntrain_df = dt.fread(path/'riiid-test-answer-prediction/train.csv', columns=set(data_types_dict.keys())).to_pandas()","execution_count":4,"outputs":[{"output_type":"stream","text":"CPU times: user 1min 3s, sys: 11 s, total: 1min 14s\nWall time: 2min 18s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":5,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 101230332 entries, 0 to 101230331\nData columns (total 7 columns):\n #   Column                          Dtype  \n---  ------                          -----  \n 0   timestamp                       int64  \n 1   user_id                         int32  \n 2   content_id                      int32  \n 3   content_type_id                 bool   \n 4   answered_correctly              int32  \n 5   prior_question_elapsed_time     float64\n 6   prior_question_had_explanation  object \ndtypes: bool(1), float64(1), int32(3), int64(1), object(1)\nmemory usage: 3.5+ GB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_df = train_df[train_df.content_type_id == False]\n\n#arrange by timestamp\ntrain_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)","execution_count":6,"outputs":[{"output_type":"stream","text":"CPU times: user 25.6 s, sys: 8.64 s, total: 34.2 s\nWall time: 34.7 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df['timestamp']\ndel train_df['content_type_id']","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pre-process"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_skill = train_df[\"content_id\"].nunique()\nprint(\"number skills\", n_skill)","execution_count":8,"outputs":[{"output_type":"stream","text":"number skills 13523\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ngroup = train_df[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (r['content_id'].values, r['answered_correctly'].values))\n\ndel train_df","execution_count":9,"outputs":[{"output_type":"stream","text":"CPU times: user 33.8 s, sys: 1.98 s, total: 35.8 s\nWall time: 36 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Data Loaders"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQ = 300\nACCEPTED_USER_CONTENT_SIZE = 6\nEMBED_SIZE = 160\nBATCH_SIZE = 64\nDROPOUT = 0.1","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SAKTDataset(Dataset):\n    def __init__(self, group, n_skill, max_seq=100):\n        super(SAKTDataset, self).__init__()\n        self.samples, self.n_skill, self.max_seq = {}, n_skill, max_seq\n        \n        self.user_ids = []\n        for i, user_id in enumerate(group.index):\n            if(i % 10000 == 0):\n                print(f'Processed {i} users')\n            content_id, answered_correctly = group[user_id]\n            if len(content_id) >= ACCEPTED_USER_CONTENT_SIZE:\n                if len(content_id) > self.max_seq:\n                    total_questions = len(content_id)\n                    last_pos = total_questions // self.max_seq\n                    for seq in range(last_pos):\n                        index = f\"{user_id}_{seq}\"\n                        self.user_ids.append(index)\n                        start = seq * self.max_seq\n                        end = (seq + 1) * self.max_seq\n                        self.samples[index] = (content_id[start:end], answered_correctly[start:end])\n                    if len(content_id[end:]) >= ACCEPTED_USER_CONTENT_SIZE:\n                        index = f\"{user_id}_{last_pos + 1}\"\n                        self.user_ids.append(index)\n                        self.samples[index] = (content_id[end:], answered_correctly[end:])\n                else:\n                    index = f'{user_id}'\n                    self.user_ids.append(index)\n                    self.samples[index] = (content_id, answered_correctly)\n                \n                \n    def __len__(self):\n        return len(self.user_ids)\n\n    def __getitem__(self, index):\n        user_id = self.user_ids[index]\n        content_id, answered_correctly = self.samples[user_id]\n        seq_len = len(content_id)\n        \n        content_id_seq = np.zeros(self.max_seq, dtype=int)\n        answered_correctly_seq = np.zeros(self.max_seq, dtype=int)\n        if seq_len >= self.max_seq:\n            content_id_seq[:] = content_id[-self.max_seq:]\n            answered_correctly_seq[:] = answered_correctly[-self.max_seq:]\n        else:\n            content_id_seq[-seq_len:] = content_id\n            answered_correctly_seq[-seq_len:] = answered_correctly\n            \n        target_id = content_id_seq[1:]\n        label = answered_correctly_seq[1:]\n        \n        x = content_id_seq[:-1].copy()\n        x += (answered_correctly_seq[:-1] == 1) * self.n_skill\n        \n        return x, target_id, label","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_SIZE = 0.1\n\ntrain, val = train_test_split(group, test_size = TEST_SIZE)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = SAKTDataset(train, n_skill, max_seq=MAX_SEQ)\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\ndel train","execution_count":13,"outputs":[{"output_type":"stream","text":"Processed 0 users\nProcessed 10000 users\nProcessed 20000 users\nProcessed 30000 users\nProcessed 40000 users\nProcessed 50000 users\nProcessed 60000 users\nProcessed 70000 users\nProcessed 80000 users\nProcessed 90000 users\nProcessed 100000 users\nProcessed 110000 users\nProcessed 120000 users\nProcessed 130000 users\nProcessed 140000 users\nProcessed 150000 users\nProcessed 160000 users\nProcessed 170000 users\nProcessed 180000 users\nProcessed 190000 users\nProcessed 200000 users\nProcessed 210000 users\nProcessed 220000 users\nProcessed 230000 users\nProcessed 240000 users\nProcessed 250000 users\nProcessed 260000 users\nProcessed 270000 users\nProcessed 280000 users\nProcessed 290000 users\nProcessed 300000 users\nProcessed 310000 users\nProcessed 320000 users\nProcessed 330000 users\nProcessed 340000 users\nProcessed 350000 users\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dataset = SAKTDataset(val, n_skill, max_seq=MAX_SEQ)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\ndel val","execution_count":14,"outputs":[{"output_type":"stream","text":"Processed 0 users\nProcessed 10000 users\nProcessed 20000 users\nProcessed 30000 users\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_batch = next(iter(train_dataloader))\nsample_batch[0].shape, sample_batch[1].shape, sample_batch[2].shape","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(torch.Size([64, 199]), torch.Size([64, 199]), torch.Size([64, 199]))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Define model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self, state_size = 200, forward_expansion = 1, bn_size=MAX_SEQ - 1, dropout=0.2):\n        super(FFN, self).__init__()\n        self.state_size = state_size\n        \n        self.lr1 = nn.Linear(state_size, forward_expansion * state_size)\n        self.relu = nn.ReLU()\n        self.bn = nn.BatchNorm1d(bn_size)\n        self.lr2 = nn.Linear(forward_expansion * state_size, state_size)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        x = self.relu(self.lr1(x))\n        x = self.bn(x)\n        x = self.lr2(x)\n        return self.dropout(x)\n\nFFN()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"FFN(\n  (lr1): Linear(in_features=200, out_features=200, bias=True)\n  (relu): ReLU()\n  (bn): BatchNorm1d(199, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (lr2): Linear(in_features=200, out_features=200, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def future_mask(seq_length):\n    future_mask = (np.triu(np.ones([seq_length, seq_length]), k = 1)).astype('bool')\n    return torch.from_numpy(future_mask)\n\nfuture_mask(5)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"tensor([[False,  True,  True,  True,  True],\n        [False, False,  True,  True,  True],\n        [False, False, False,  True,  True],\n        [False, False, False, False,  True],\n        [False, False, False, False, False]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, embed_dim, heads = 8, dropout = DROPOUT, forward_expansion = 1):\n        super(TransformerBlock, self).__init__()\n        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=heads, dropout=dropout)\n        self.dropout = nn.Dropout(dropout)\n        self.layer_normal = nn.LayerNorm(embed_dim)\n        self.ffn = FFN(embed_dim, forward_expansion = forward_expansion, dropout=dropout)\n        self.layer_normal_2 = nn.LayerNorm(embed_dim)\n        \n\n    def forward(self, value, key, query, att_mask):\n        att_output, att_weight = self.multi_att(value, key, query, attn_mask=att_mask)\n        att_output = self.dropout(self.layer_normal(att_output + value))\n        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n        x = self.ffn(att_output)\n        x = self.dropout(self.layer_normal_2(x + att_output))\n        return x.squeeze(-1), att_weight\n    \nclass Encoder(nn.Module):\n    def __init__(self, n_skill, max_seq=100, embed_dim=128, dropout = DROPOUT, forward_expansion = 1, num_layers=1, heads = 8):\n        super(Encoder, self).__init__()\n        self.n_skill, self.embed_dim = n_skill, embed_dim\n        self.embedding = nn.Embedding(2 * n_skill + 1, embed_dim)\n        self.pos_embedding = nn.Embedding(max_seq - 1, embed_dim)\n        self.e_embedding = nn.Embedding(n_skill+1, embed_dim)\n        self.layers = nn.ModuleList([TransformerBlock(embed_dim, forward_expansion = forward_expansion) for _ in range(num_layers)])\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, question_ids):\n        device = x.device\n        x = self.embedding(x)\n        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n        pos_x = self.pos_embedding(pos_id)\n        x = self.dropout(x + pos_x)\n        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n        e = self.e_embedding(question_ids)\n        e = e.permute(1, 0, 2)\n        for layer in self.layers:\n            att_mask = future_mask(e.size(0)).to(device)\n            x, att_weight = layer(e, x, x, att_mask=att_mask)\n            x = x.permute(1, 0, 2)\n        x = x.permute(1, 0, 2)\n        return x, att_weight\n\nclass SAKTModel(nn.Module):\n    def __init__(self, n_skill, max_seq=100, embed_dim=128, dropout = DROPOUT, forward_expansion = 1, enc_layers=1, heads = 8):\n        super(SAKTModel, self).__init__()\n        self.encoder = Encoder(n_skill, max_seq, embed_dim, dropout, forward_expansion, num_layers=enc_layers)\n        self.pred = nn.Linear(embed_dim, 1)\n        \n    def forward(self, x, question_ids):\n        x, att_weight = self.encoder(x, question_ids)\n        x = self.pred(x)\n        return x.squeeze(-1), att_weight","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Main changes are possibility of forward expansion and stacking of encoding layers\ndef create_model():\n    return SAKTModel(n_skill, max_seq=MAX_SEQ, embed_dim=EMBED_SIZE, forward_expansion=1, enc_layers=1, heads=8, dropout=0.1)\nmodel = create_model()\nmodel","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"SAKTModel(\n  (encoder): Encoder(\n    (embedding): Embedding(27047, 160)\n    (pos_embedding): Embedding(199, 160)\n    (e_embedding): Embedding(13524, 160)\n    (layers): ModuleList(\n      (0): TransformerBlock(\n        (multi_att): MultiheadAttention(\n          (out_proj): _LinearWithBias(in_features=160, out_features=160, bias=True)\n        )\n        (dropout): Dropout(p=0.1, inplace=False)\n        (layer_normal): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n        (ffn): FFN(\n          (lr1): Linear(in_features=160, out_features=160, bias=True)\n          (relu): ReLU()\n          (bn): BatchNorm1d(199, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (lr2): Linear(in_features=160, out_features=160, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_normal_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (pred): Linear(in_features=160, out_features=1, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(sample_batch[0], sample_batch[1])[0]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"tensor([[ 0.0943,  0.1150,  0.0849,  ...,  0.2284, -0.6651,  0.8758],\n        [-0.8728, -0.0165, -0.2498,  ...,  0.1810,  0.2722, -0.8297],\n        [ 1.0165, -0.2681, -0.6368,  ..., -0.2659,  0.1405,  1.0754],\n        ...,\n        [ 0.7073,  0.6413,  0.1784,  ..., -0.3170,  0.2370, -0.5412],\n        [-0.3741, -0.1135,  0.1224,  ..., -0.1214, -0.7125, -1.4640],\n        [ 0.1593, -1.1721, -0.7280,  ...,  0.0277, -0.7164, -1.3595]],\n       grad_fn=<SqueezeBackward1>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 2e-3\nEPOCHS = 10\nMODEL_PATH = '/kaggle/working/sakt.pth'","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_from_item(item):\n    x = item[0].to(device).long()\n    target_id = item[1].to(device).long()\n    label = item[2].to(device).float()\n    target_mask = (target_id != 0)\n    return x, target_id, label, target_mask\n\ndef update_stats(tbar, train_loss, loss, output, label, num_corrects, num_total, labels, outs):\n    train_loss.append(loss.item())\n    pred = (torch.sigmoid(output) >= 0.5).long()\n    num_corrects += (pred == label).sum().item()\n    num_total += len(label)\n    labels.extend(label.view(-1).data.cpu().numpy())\n    outs.extend(output.view(-1).data.cpu().numpy())\n    tbar.set_description('loss - {:.4f}'.format(loss))\n    return num_corrects, num_total\n\ndef train_epoch(model, dataloader, optim, criterion, scheduler, device=\"cpu\"):\n    model.train()\n    \n    train_loss = []\n    num_corrects = 0\n    num_total = 0\n    labels = []\n    outs = []\n    \n    tbar = tqdm(dataloader)\n    for item in tbar:\n        x, target_id, label, target_mask = load_from_item(item)\n        \n        optim.zero_grad()\n        output, _ = model(x, target_id)\n        \n        output = torch.masked_select(output, target_mask)\n        label = torch.masked_select(label, target_mask)\n        \n        loss = criterion(output, label)\n        loss.backward()\n        optim.step()\n        scheduler.step()\n        \n        tbar.set_description('loss - {:.4f}'.format(loss))\n\ndef val_epoch(model, val_iterator, criterion, device=\"cpu\"):\n    model.eval()\n\n    train_loss = []\n    num_corrects = 0\n    num_total = 0\n    labels = []\n    outs = []\n\n    tbar = tqdm(val_iterator)\n    for item in tbar:\n        x, target_id, label, target_mask = load_from_item(item)\n\n        with torch.no_grad():\n            output, atten_weight = model(x, target_id)\n        \n        output = torch.masked_select(output, target_mask)\n        label = torch.masked_select(label, target_mask)\n\n        loss = criterion(output, label)\n        \n        num_corrects, num_total = update_stats(tbar, train_loss, loss, output, label, num_corrects, num_total, labels, outs)\n\n    acc = num_corrects / num_total\n    auc = roc_auc_score(labels, outs)\n    loss = np.average(train_loss)\n\n    return loss, acc, auc\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_train():\n    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n    criterion = nn.BCEWithLogitsLoss()\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR, \n                                                    steps_per_epoch=len(train_dataloader), epochs=EPOCHS)\n    model.to(device)\n    criterion.to(device)\n    best_auc = 0.0\n    for epoch in range(EPOCHS):\n        train_epoch(model, train_dataloader, optimizer, criterion, scheduler, device)\n        val_loss, avl_acc, val_auc = val_epoch(model, val_dataloader, criterion, device)\n        print(f\"epoch - {epoch + 1} val_loss - {val_loss:.3f} acc - {avl_acc:.3f} auc - {val_auc:.3f}\")\n        if best_auc < val_auc:\n            print(f'epoch - {epoch + 1} best model with val auc: {val_auc}')\n            best_auc = val_auc\n        torch.save(model.state_dict(), MODEL_PATH)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_train()","execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6425cb951480486ebdd133c76548504f"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0262c5add04e4e8ee0c33774861a0d"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 1 val_loss - 0.546 acc - 0.720 auc - 0.755\nepoch - 1 best model with val auc: 0.7551630849213927\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"233bd53a5b504be4b3c63364dfdd775d"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aace38d4ccb141d39dbded9a000afc31"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 2 val_loss - 0.542 acc - 0.723 auc - 0.760\nepoch - 2 best model with val auc: 0.7603297334452226\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3abd479a9e7c4ac3beef13a8fea29ecc"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea5c2cdf08f24ada909ae0df403f5d21"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 3 val_loss - 0.540 acc - 0.725 auc - 0.762\nepoch - 3 best model with val auc: 0.7624096820992651\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64fd54a615414b1ca32e296c229af3ee"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd9564fbdefb4688a30575671de9a599"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 4 val_loss - 0.538 acc - 0.726 auc - 0.765\nepoch - 4 best model with val auc: 0.7646272270013406\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7994dbd0ceec4eda893b3771327c0100"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e2dca585381474b8316998e308c43a5"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 5 val_loss - 0.536 acc - 0.728 auc - 0.767\nepoch - 5 best model with val auc: 0.7666810129457177\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1395b60d00a4975acdfae18946ceb4c"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9060ed83579c4711a17daf830ae355f8"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 6 val_loss - 0.535 acc - 0.728 auc - 0.768\nepoch - 6 best model with val auc: 0.768221956624451\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4395215ed9843c5b19ed132f4e0c8e7"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7571ae588c4f46cc9165aa5ed5749b12"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 7 val_loss - 0.534 acc - 0.729 auc - 0.769\nepoch - 7 best model with val auc: 0.7691953766753178\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bde04728ec54f76b2bd24e4b289f821"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fc996c736954fcf990f3f725a66a9fb"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 8 val_loss - 0.534 acc - 0.730 auc - 0.770\nepoch - 8 best model with val auc: 0.7698938913945348\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dd0057a050944c89e6b28d8268aac9f"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3be20cd0e3d4ab18e0a49e6ff58a8ea"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 9 val_loss - 0.533 acc - 0.730 auc - 0.770\nepoch - 9 best model with val auc: 0.7702504679861872\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b577251440b4b9e9a19105322d87473"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf3d17c55d34fb1974f9bc906ce51a4"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 10 val_loss - 0.533 acc - 0.730 auc - 0.770\nepoch - 10 best model with val auc: 0.7702711220510581\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 2e-4\nEPOCHS = 3\n\ndo_train()","execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62cf0d71ea0941b8b711cadf45541665"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58dae272c4cb44939a486c6d7d12e1c7"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 1 val_loss - 0.533 acc - 0.730 auc - 0.770\nepoch - 1 best model with val auc: 0.7701357001358361\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49e23ba431b94d0c95f616efcab53dd4"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6879dedb0dbb40bd8e8bc3349afdc81d"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 2 val_loss - 0.533 acc - 0.730 auc - 0.770\nepoch - 2 best model with val auc: 0.7702864117422439\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10856.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"513fb0e0b4d34e46ac4d0e77e62af0b1"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1208.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29af824ce7d940be89a9690521801329"}},"metadata":{}},{"output_type":"stream","text":"\nepoch - 3 val_loss - 0.533 acc - 0.730 auc - 0.770\nepoch - 3 best model with val auc: 0.7703158213188511\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.load_state_dict(torch.load(MODEL_PATH))\nmodel.to(device)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"SAKTModel(\n  (encoder): Encoder(\n    (embedding): Embedding(27047, 160)\n    (pos_embedding): Embedding(199, 160)\n    (e_embedding): Embedding(13524, 160)\n    (layers): ModuleList(\n      (0): TransformerBlock(\n        (multi_att): MultiheadAttention(\n          (out_proj): _LinearWithBias(in_features=160, out_features=160, bias=True)\n        )\n        (dropout): Dropout(p=0.1, inplace=False)\n        (layer_normal): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n        (ffn): FFN(\n          (lr1): Linear(in_features=160, out_features=160, bias=True)\n          (relu): ReLU()\n          (bn): BatchNorm1d(199, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (lr2): Linear(in_features=160, out_features=160, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (layer_normal_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (pred): Linear(in_features=160, out_features=1, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, samples, test_df, n_skill, max_seq=100):\n        super(TestDataset, self).__init__()\n        self.samples, self.user_ids, self.test_df = samples, [x for x in test_df[\"user_id\"].unique()], test_df\n        self.n_skill, self.max_seq = n_skill, max_seq\n\n    def __len__(self):\n        return self.test_df.shape[0]\n    \n    def __getitem__(self, index):\n        test_info = self.test_df.iloc[index]\n        \n        user_id = test_info['user_id']\n        target_id = test_info['content_id']\n        \n        content_id_seq = np.zeros(self.max_seq, dtype=int)\n        answered_correctly_seq = np.zeros(self.max_seq, dtype=int)\n        \n        if user_id in self.samples.index:\n            content_id, answered_correctly = self.samples[user_id]\n            \n            seq_len = len(content_id)\n            \n            if seq_len >= self.max_seq:\n                content_id_seq = content_id[-self.max_seq:]\n                answered_correctly_seq = answered_correctly[-self.max_seq:]\n            else:\n                content_id_seq[-seq_len:] = content_id\n                answered_correctly_seq[-seq_len:] = answered_correctly\n                \n        x = content_id_seq[1:].copy()\n        x += (answered_correctly_seq[1:] == 1) * self.n_skill\n        \n        questions = np.append(content_id_seq[2:], [target_id])\n        \n        return x, questions","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\n\nenv = riiideducation.make_env()\niter_test = env.iter_test()","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import psutil\n\nmodel.eval()\n\nprev_test_df = None\n\nfor (test_df, sample_prediction_df) in tqdm(iter_test):\n    \n    if (prev_test_df is not None) & (psutil.virtual_memory().percent<90):\n        print(psutil.virtual_memory().percent)\n        prev_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n        prev_test_df = prev_test_df[prev_test_df.content_type_id == False]\n        prev_group = prev_test_df[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n            r['content_id'].values,\n            r['answered_correctly'].values))\n        for prev_user_id in prev_group.index:\n            prev_group_content = prev_group[prev_user_id][0]\n            prev_group_answered_correctly = prev_group[prev_user_id][1]\n            if prev_user_id in group.index:\n                group[prev_user_id] = (np.append(group[prev_user_id][0], prev_group_content), \n                                       np.append(group[prev_user_id][1], prev_group_answered_correctly))\n            else:\n                group[prev_user_id] = (prev_group_content, prev_group_answered_correctly)\n            \n            if len(group[prev_user_id][0]) > MAX_SEQ:\n                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n                new_group_answered_correctly = group[prev_user_id][1][-MAX_SEQ:]\n                group[prev_user_id] = (new_group_content, new_group_answered_correctly)\n                \n    prev_test_df = test_df.copy()\n    test_df = test_df[test_df.content_type_id == False]\n    \n    test_dataset = TestDataset(group, test_df, n_skill, max_seq=MAX_SEQ)\n    test_dataloader = DataLoader(test_dataset, batch_size=len(test_df), shuffle=False)\n    \n    item = next(iter(test_dataloader))\n    x = item[0].to(device).long()\n    target_id = item[1].to(device).long()\n    \n    with torch.no_grad():\n        output, _ = model(x, target_id)\n        \n    output = torch.sigmoid(output)\n    output = output[:, -1]\n    test_df['answered_correctly'] = output.cpu().numpy()\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2d9536fbfaa4f328e696998589ef56f"}},"metadata":{}},{"output_type":"stream","text":"29.1\n29.1\n29.1\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"           row_id    timestamp     user_id  content_id  content_type_id  \\\ngroup_num                                                                 \n3              74        75311   275030867        8308                0   \n3              75  31220886463  1305988022         396                0   \n3              76  48613916248  1310228392       11869                0   \n3              77  48613916248  1310228392       11871                0   \n3              78  48613916248  1310228392       11870                0   \n3              79  48613916248  1310228392       11872                0   \n3              80  48613916248  1310228392       11868                0   \n3              81   4693192735  1637273633        5935                0   \n3              82   1254131274   674533997        6000                0   \n3              84  69704234415  2093197291       12611                0   \n3              86  32722404604  1202386221         438                0   \n3              87   2379177011  1468996389        2470                0   \n3              88   2379177011  1468996389        2471                0   \n3              89   2379177011  1468996389        2472                0   \n3              90  44526385962   555691277         573                0   \n3              91  60813397921  1838324752       10435                0   \n3              92  23890386630  2103436554        1722                0   \n3              93  23890386630  2103436554        1721                0   \n3              94  23890386630  2103436554        1723                0   \n3              95  27465573535   311890082        2029                0   \n3              96  27465573535   311890082        2028                0   \n3              97  27465573535   311890082        2027                0   \n3              98   1367936449  1817433235       12135                0   \n3              99   2214847937   998511398       10646                0   \n3             100    516880082  1422853669        1098                0   \n3             101  13309987002   554169193        1043                0   \n3             102  39457020766  1317245193       12145                0   \n3             103  13167339284  1900527744        3005                0   \n3             104  13167339284  1900527744        3004                0   \n3             105  13167339284  1900527744        3003                0   \n3             106  64497673060     7792299        7908                0   \n3             107  62798166743   288641214        9077                0   \n3             108   2059176357  2018567473       12119                0   \n\n           task_container_id  prior_question_elapsed_time  \\\ngroup_num                                                   \n3                          3                      15000.0   \n3                       4163                      19000.0   \n3                       1458                      26333.0   \n3                       1458                      26333.0   \n3                       1458                      26333.0   \n3                       1458                      26333.0   \n3                       1458                      26333.0   \n3                       3149                      19000.0   \n3                       1046                      10000.0   \n3                       5448                      28750.0   \n3                        139                      17000.0   \n3                        230                      26000.0   \n3                        230                      26000.0   \n3                        230                      26000.0   \n3                         54                      18000.0   \n3                        299                      26000.0   \n3                       1033                      23333.0   \n3                       1033                      23333.0   \n3                       1033                      23333.0   \n3                        212                      26000.0   \n3                        212                      26000.0   \n3                        212                      26000.0   \n3                        392                       7000.0   \n3                        395                      26000.0   \n3                         87                      22000.0   \n3                       4429                      18000.0   \n3                       5317                      17000.0   \n3                       1179                      24667.0   \n3                       1179                      24667.0   \n3                       1179                      24667.0   \n3                        676                      19000.0   \n3                        269                      25000.0   \n3                        591                      20000.0   \n\n           prior_question_had_explanation  \\\ngroup_num                                   \n3                                   False   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n3                                    True   \n\n                                 prior_group_answers_correct  \\\ngroup_num                                                      \n3          [1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, ...   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n\n                                       prior_group_responses  \\\ngroup_num                                                      \n3          [0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 3, 0, 0, ...   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n3                                                        NaN   \n\n           answered_correctly  \ngroup_num                      \n3                    0.421837  \n3                    0.555399  \n3                    0.440757  \n3                    0.972952  \n3                    0.534407  \n3                    0.440011  \n3                    0.953311  \n3                    0.834655  \n3                    0.381240  \n3                    0.835074  \n3                    0.594277  \n3                    0.788149  \n3                    0.990099  \n3                    0.973489  \n3                    0.871003  \n3                    0.851761  \n3                    0.734626  \n3                    0.869370  \n3                    0.832509  \n3                    0.773620  \n3                    0.289082  \n3                    0.466042  \n3                    0.977395  \n3                    0.782270  \n3                    0.678498  \n3                    0.718442  \n3                    0.703236  \n3                    0.877448  \n3                    0.534685  \n3                    0.842630  \n3                    0.752668  \n3                    0.676068  \n3                    0.973836  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>timestamp</th>\n      <th>user_id</th>\n      <th>content_id</th>\n      <th>content_type_id</th>\n      <th>task_container_id</th>\n      <th>prior_question_elapsed_time</th>\n      <th>prior_question_had_explanation</th>\n      <th>prior_group_answers_correct</th>\n      <th>prior_group_responses</th>\n      <th>answered_correctly</th>\n    </tr>\n    <tr>\n      <th>group_num</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>74</td>\n      <td>75311</td>\n      <td>275030867</td>\n      <td>8308</td>\n      <td>0</td>\n      <td>3</td>\n      <td>15000.0</td>\n      <td>False</td>\n      <td>[1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, ...</td>\n      <td>[0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 3, 0, 0, ...</td>\n      <td>0.421837</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75</td>\n      <td>31220886463</td>\n      <td>1305988022</td>\n      <td>396</td>\n      <td>0</td>\n      <td>4163</td>\n      <td>19000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.555399</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>76</td>\n      <td>48613916248</td>\n      <td>1310228392</td>\n      <td>11869</td>\n      <td>0</td>\n      <td>1458</td>\n      <td>26333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.440757</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>77</td>\n      <td>48613916248</td>\n      <td>1310228392</td>\n      <td>11871</td>\n      <td>0</td>\n      <td>1458</td>\n      <td>26333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.972952</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>78</td>\n      <td>48613916248</td>\n      <td>1310228392</td>\n      <td>11870</td>\n      <td>0</td>\n      <td>1458</td>\n      <td>26333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.534407</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>79</td>\n      <td>48613916248</td>\n      <td>1310228392</td>\n      <td>11872</td>\n      <td>0</td>\n      <td>1458</td>\n      <td>26333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.440011</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80</td>\n      <td>48613916248</td>\n      <td>1310228392</td>\n      <td>11868</td>\n      <td>0</td>\n      <td>1458</td>\n      <td>26333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.953311</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81</td>\n      <td>4693192735</td>\n      <td>1637273633</td>\n      <td>5935</td>\n      <td>0</td>\n      <td>3149</td>\n      <td>19000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.834655</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>82</td>\n      <td>1254131274</td>\n      <td>674533997</td>\n      <td>6000</td>\n      <td>0</td>\n      <td>1046</td>\n      <td>10000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.381240</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84</td>\n      <td>69704234415</td>\n      <td>2093197291</td>\n      <td>12611</td>\n      <td>0</td>\n      <td>5448</td>\n      <td>28750.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.835074</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>86</td>\n      <td>32722404604</td>\n      <td>1202386221</td>\n      <td>438</td>\n      <td>0</td>\n      <td>139</td>\n      <td>17000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.594277</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>87</td>\n      <td>2379177011</td>\n      <td>1468996389</td>\n      <td>2470</td>\n      <td>0</td>\n      <td>230</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.788149</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>88</td>\n      <td>2379177011</td>\n      <td>1468996389</td>\n      <td>2471</td>\n      <td>0</td>\n      <td>230</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.990099</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>89</td>\n      <td>2379177011</td>\n      <td>1468996389</td>\n      <td>2472</td>\n      <td>0</td>\n      <td>230</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.973489</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>90</td>\n      <td>44526385962</td>\n      <td>555691277</td>\n      <td>573</td>\n      <td>0</td>\n      <td>54</td>\n      <td>18000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.871003</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>91</td>\n      <td>60813397921</td>\n      <td>1838324752</td>\n      <td>10435</td>\n      <td>0</td>\n      <td>299</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.851761</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>92</td>\n      <td>23890386630</td>\n      <td>2103436554</td>\n      <td>1722</td>\n      <td>0</td>\n      <td>1033</td>\n      <td>23333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.734626</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>93</td>\n      <td>23890386630</td>\n      <td>2103436554</td>\n      <td>1721</td>\n      <td>0</td>\n      <td>1033</td>\n      <td>23333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.869370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>94</td>\n      <td>23890386630</td>\n      <td>2103436554</td>\n      <td>1723</td>\n      <td>0</td>\n      <td>1033</td>\n      <td>23333.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.832509</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>95</td>\n      <td>27465573535</td>\n      <td>311890082</td>\n      <td>2029</td>\n      <td>0</td>\n      <td>212</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.773620</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96</td>\n      <td>27465573535</td>\n      <td>311890082</td>\n      <td>2028</td>\n      <td>0</td>\n      <td>212</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.289082</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>97</td>\n      <td>27465573535</td>\n      <td>311890082</td>\n      <td>2027</td>\n      <td>0</td>\n      <td>212</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.466042</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>98</td>\n      <td>1367936449</td>\n      <td>1817433235</td>\n      <td>12135</td>\n      <td>0</td>\n      <td>392</td>\n      <td>7000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.977395</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>99</td>\n      <td>2214847937</td>\n      <td>998511398</td>\n      <td>10646</td>\n      <td>0</td>\n      <td>395</td>\n      <td>26000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.782270</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>516880082</td>\n      <td>1422853669</td>\n      <td>1098</td>\n      <td>0</td>\n      <td>87</td>\n      <td>22000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.678498</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>101</td>\n      <td>13309987002</td>\n      <td>554169193</td>\n      <td>1043</td>\n      <td>0</td>\n      <td>4429</td>\n      <td>18000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.718442</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>102</td>\n      <td>39457020766</td>\n      <td>1317245193</td>\n      <td>12145</td>\n      <td>0</td>\n      <td>5317</td>\n      <td>17000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.703236</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>103</td>\n      <td>13167339284</td>\n      <td>1900527744</td>\n      <td>3005</td>\n      <td>0</td>\n      <td>1179</td>\n      <td>24667.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.877448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104</td>\n      <td>13167339284</td>\n      <td>1900527744</td>\n      <td>3004</td>\n      <td>0</td>\n      <td>1179</td>\n      <td>24667.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.534685</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105</td>\n      <td>13167339284</td>\n      <td>1900527744</td>\n      <td>3003</td>\n      <td>0</td>\n      <td>1179</td>\n      <td>24667.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.842630</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106</td>\n      <td>64497673060</td>\n      <td>7792299</td>\n      <td>7908</td>\n      <td>0</td>\n      <td>676</td>\n      <td>19000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.752668</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>107</td>\n      <td>62798166743</td>\n      <td>288641214</td>\n      <td>9077</td>\n      <td>0</td>\n      <td>269</td>\n      <td>25000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.676068</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>108</td>\n      <td>2059176357</td>\n      <td>2018567473</td>\n      <td>12119</td>\n      <td>0</td>\n      <td>591</td>\n      <td>20000.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.973836</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = TestDataset(group, test_df, n_skill, max_seq=MAX_SEQ)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save to pickle to usage in other notebooks\ngroup.to_pickle('/kaggle/working/group.pkl')","execution_count":33,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}