{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Colab Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "COLAB = True\n",
    "KAGGLE = False\n",
    "DOWNLOAD_DATA = True\n",
    "SAVE_TO_GITHUB = False\n",
    "GIT_REPOSITORY = \"osic-pulmonary-fibrosis-progression\"\n",
    "FILE_NAME = \"main.ipynb\"\n",
    "\n",
    "if COLAB:\n",
    "    PARENT_DIRECTORY_PATH = \"/content\"\n",
    "    # In case you want to clone in your drive:\n",
    "    # PARENT_DIRECTORY_PATH = \"/content/gdrive/My Drive\"\n",
    "    PROJECT_PATH = PARENT_DIRECTORY_PATH + \"/\" + GIT_REPOSITORY\n",
    "    %cd \"{PARENT_DIRECTORY_PATH}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linking personal Google Drive storage with Google Colab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mounting is the process by which the os makes files and directories of a\n",
    "storage service (google drive) available for the users via the computer's\n",
    "file system. Log in will be required."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    %cd /content\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/gdrive\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clone GitHub repository to Colab Runtime system"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    import json\n",
    "\n",
    "    with open(\"/content/gdrive/My Drive/Git/git.json\", \"r\") as f:\n",
    "        parsed_json = json.load(f)\n",
    "\n",
    "    GIT_USER_NAME = parsed_json[\"GIT_USER_NAME\"]\n",
    "    GIT_TOKEN = parsed_json[\"GIT_TOKEN\"]\n",
    "    GIT_USER_EMAIL = parsed_json[\"GIT_USER_EMAIL\"]\n",
    "\n",
    "    GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{GIT_USER_NAME}/{GIT_REPOSITORY}.git\"\n",
    "\n",
    "    %cd \"{PARENT_DIRECTORY_PATH}\"\n",
    "\n",
    "    !git clone \"{GIT_PATH}\"  # Clone the github repository\n",
    "\n",
    "    %cd \"{PROJECT_PATH}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kaggle API Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the following code to provide the config path to kaggle.json\n",
    "(api credentials)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    import os\n",
    "\n",
    "    os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/gdrive/My Drive/Kaggle\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download the data using the API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before start downloading the data, make sure u are in a directory outside\n",
    "your Google Drive; otherwise, u will put the data there and you will reach\n",
    "the limit storage easily."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if DOWNLOAD_DATA:\n",
    "    !mkdir input\n",
    "    %cd input\n",
    "\n",
    "    !pip install --upgrade kaggle\n",
    "    # Go to kaggle and copy the API Command to download the dataset\n",
    "    # !kaggle competitions download -c {GIT_REPOSITORY}\n",
    "    # Instead of downloading all data, we select specific files.\n",
    "    !kaggle competitions download {GIT_REPOSITORY} -f train.csv\n",
    "    !kaggle competitions download {GIT_REPOSITORY} -f test.csv\n",
    "    !kaggle competitions download {GIT_REPOSITORY} -f sample_submission.csv\n",
    "\n",
    "    # Unzipping the zip files and deleting the zip files\n",
    "    !unzip \\*.zip  && rm *.zip\n",
    "\n",
    "    # After downloading all data, go back to PROJECT_PATH\n",
    "    %cd ..\n",
    "\n",
    "if KAGGLE:\n",
    "    INPUT_ROOT = f\"../input/{GIT_REPOSITORY}\"\n",
    "else:\n",
    "    INPUT_ROOT = f\"../{GIT_REPOSITORY}/input\"\n",
    "\n",
    "# INPUT_ROOT will be used as follows\n",
    "# train_df = pd.read_csv(f\"{INPUT_ROOT}/train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save changes to GitHub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SAVE_TO_GITHUB:\n",
    "    !git add {FILE_NAME}\n",
    "    !git config --global user.email {GIT_USER_EMAIL}\n",
    "    !git config --global user.name {GIT_USER_NAME}\n",
    "    !git commit -am \"update {FILE_NAME}\"\n",
    "    !git push"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## \"Improvement of optimized LightGBM with Optuna adding SAKT Model\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Points:\n",
    "1. This Notebook is based on [Riiid LGBM bagging2 + SAKT =0.781](https://www.kaggle.com/ammarnassanalhajali/riiid-lgbm-bagging2-sakt-0-781);\n",
    "1. I use optimized parameters with Optuna for it;\n",
    "1. This version added visualization and empirical analysis of the submission."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Source Notebooks:\n",
    "1. [SAKT + Riiid LGBM bagging2 LB 0.780](https://www.kaggle.com/leadbest/sakt-riiid-lgbm-bagging2)\n",
    "1. [SAKT with Randomization & State Updates LB0.771](https://www.kaggle.com/leadbest/sakt-with-randomization-state-updates)\n",
    "1. [Riiid! LGBM bagging2 LB0.772](https://www.kaggle.com/zephyrwang666/riiid-lgbm-bagging2)\n",
    "1. [Riiid LGBM bagging2 + SAKT =0.781](https://www.kaggle.com/ammarnassanalhajali/riiid-lgbm-bagging2-sakt-0-781/output?select=group.pkl)\n",
    "1. [Riiid!: Optimized LightGBM with Optuna](https://www.kaggle.com/satorushibata/riiid-optimized-lightgbm-with-optuna?scriptVersionId=50192148)\n",
    "    - The parameters were generated in [LightGBM on GPU with Feature Engineering, Optuna, and, Visualization](https://github.com/satorushibata0627/Publishment/blob/main/Kaggle_Python3_LightGBM_on_GPU_with_Feature_Engineering_Optuna_and_Visualization.ipynb).\n",
    "1. [Fork of Riiid LGBM bagging2.1 471152](https://www.kaggle.com/julianguo/fork-of-riiid-lgbm-bagging2-1-471152)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note\n",
    "1. Congratulations to [@若人生只若初见](https://www.kaggle.com/julianguo)!\n",
    "1. The Notebook: [Fork of Riiid LGBM bagging2.1 471152](https://www.kaggle.com/julianguo/fork-of-riiid-lgbm-bagging2-1-471152) achieved Public Score = 0.783."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import datatable as dt\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import riiideducation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "_ = np.seterr(divide=\"ignore\", invalid=\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random seed\n",
    "- This idea is made by [Riiid model LGBM](https://www.kaggle.com/ragnar123/riiid-model-lgbm)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initial value\n",
    "SEED = 123\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_types_dict = {\n",
    "    \"timestamp\": \"int64\",\n",
    "    \"user_id\": \"int32\",\n",
    "    \"content_id\": \"int16\",\n",
    "    \"content_type_id\": \"int8\",\n",
    "    \"task_container_id\": \"int16\",\n",
    "    #'user_answer': 'int8',\n",
    "    \"answered_correctly\": \"int8\",\n",
    "    \"prior_question_elapsed_time\": \"float32\",\n",
    "    \"prior_question_had_explanation\": \"bool\",\n",
    "}\n",
    "target = \"answered_correctly\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = dt.fread(\n",
    "    \"../input/riiid-test-answer-prediction/train.csv\",\n",
    "    columns=set(data_types_dict.keys()),\n",
    ").to_pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(psutil.virtual_memory().percent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reading in lecture df\n",
    "lectures_df = pd.read_csv(\"/kaggle/input/riiid-test-answer-prediction/lectures.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lectures_df[\"type_of\"] = lectures_df[\"type_of\"].replace(\n",
    "    \"solving question\", \"solving_question\"\n",
    ")\n",
    "lectures_df = pd.get_dummies(lectures_df, columns=[\"part\", \"type_of\"])\n",
    "part_lectures_columns = [\n",
    "    column for column in lectures_df.columns if column.startswith(\"part\")\n",
    "]\n",
    "types_of_lectures_columns = [\n",
    "    column for column in lectures_df.columns if column.startswith(\"type_of_\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_lectures = train_df[train_df.content_type_id == True].merge(\n",
    "    lectures_df, left_on=\"content_id\", right_on=\"lecture_id\", how=\"left\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_lecture_stats_part = train_lectures.groupby(\"user_id\", as_index=False)[\n",
    "    part_lectures_columns + types_of_lectures_columns\n",
    "].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lecturedata_types_dict = {\n",
    "    \"user_id\": \"int32\",\n",
    "    \"part_1\": \"int8\",\n",
    "    \"part_2\": \"int8\",\n",
    "    \"part_3\": \"int8\",\n",
    "    \"part_4\": \"int8\",\n",
    "    \"part_5\": \"int8\",\n",
    "    \"part_6\": \"int8\",\n",
    "    \"part_7\": \"int8\",\n",
    "    \"type_of_concept\": \"int8\",\n",
    "    \"type_of_intention\": \"int8\",\n",
    "    \"type_of_solving_question\": \"int8\",\n",
    "    \"type_of_starter\": \"int8\",\n",
    "}\n",
    "user_lecture_stats_part = user_lecture_stats_part.astype(lecturedata_types_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for column in user_lecture_stats_part.columns:\n",
    "    # bool_column = column + '_boolean'\n",
    "    if column != \"user_id\":\n",
    "        user_lecture_stats_part[column] = (user_lecture_stats_part[column] > 0).astype(\n",
    "            \"int8\"\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_lectures[train_lectures.user_id == 5382]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_lecture_stats_part[user_lecture_stats_part.user_id == 5382]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_lecture_stats_part.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_lecture_stats_part.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clearing memory\n",
    "del train_lectures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(psutil.virtual_memory().percent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cum = train_df.groupby(\"user_id\")[\"content_type_id\"].agg([\"cumsum\", \"cumcount\"])\n",
    "train_df[\"user_lecture_cumsum\"] = cum[\"cumsum\"]\n",
    "train_df[\"user_lecture_lv\"] = cum[\"cumsum\"] / cum[\"cumcount\"]\n",
    "train_df.user_lecture_lv = train_df.user_lecture_lv.astype(\"float16\")\n",
    "train_df.user_lecture_cumsum = train_df.user_lecture_cumsum.astype(\"int8\")\n",
    "user_lecture_agg = train_df.groupby(\"user_id\")[\"content_type_id\"].agg([\"sum\", \"count\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"prior_question_had_explanation\"].fillna(False, inplace=True)\n",
    "train_df = train_df.astype(data_types_dict)\n",
    "train_df = train_df[train_df[target] != -1].reset_index(drop=True)\n",
    "prior_question_elapsed_time_mean = train_df[\"prior_question_elapsed_time\"].mean()\n",
    "train_df[\"prior_question_elapsed_time\"].fillna(\n",
    "    prior_question_elapsed_time_mean, inplace=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_timestamp_u = (\n",
    "    train_df[[\"user_id\", \"timestamp\"]].groupby([\"user_id\"]).agg([\"max\"]).reset_index()\n",
    ")\n",
    "# max_timestamp_u = train_df[['user_id','timestamp']].groupby(['user_id']).agg(['max'])\n",
    "max_timestamp_u.columns = [\"user_id\", \"max_time_stamp\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"lagtime\"] = train_df.groupby(\"user_id\")[\"timestamp\"].shift()\n",
    "train_df[\"lagtime\"] = train_df[\"timestamp\"] - train_df[\"lagtime\"]\n",
    "train_df[\"lagtime\"].fillna(0, inplace=True)\n",
    "train_df.lagtime = train_df.lagtime.astype(\"int32\")\n",
    "# train_df.drop(columns=['timestamp'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lagtime_agg = train_df.groupby(\"user_id\")[\"lagtime\"].agg([\"mean\"])\n",
    "train_df[\"lagtime_mean\"] = train_df[\"user_id\"].map(lagtime_agg[\"mean\"])\n",
    "train_df.lagtime_mean = train_df.lagtime_mean.astype(\"int32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_prior_question_elapsed_time = (\n",
    "    train_df[[\"user_id\", \"prior_question_elapsed_time\"]].groupby([\"user_id\"]).tail(1)\n",
    ")\n",
    "# max_timestamp_u = train_df[['user_id','timestamp']].groupby(['user_id']).agg(['max'])\n",
    "user_prior_question_elapsed_time.columns = [\"user_id\", \"prior_question_elapsed_time\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"delta_prior_question_elapsed_time\"] = train_df.groupby(\"user_id\")[\n",
    "    \"prior_question_elapsed_time\"\n",
    "].shift()\n",
    "train_df[\"delta_prior_question_elapsed_time\"] = (\n",
    "    train_df[\"prior_question_elapsed_time\"]\n",
    "    - train_df[\"delta_prior_question_elapsed_time\"]\n",
    ")\n",
    "train_df[\"delta_prior_question_elapsed_time\"].fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.delta_prior_question_elapsed_time = (\n",
    "    train_df.delta_prior_question_elapsed_time.astype(\"int32\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"timestamp\"] = train_df[\"timestamp\"] / (1000 * 3600)\n",
    "train_df.timestamp = train_df.timestamp.astype(\"int16\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"lag\"] = train_df.groupby(\"user_id\")[target].shift()\n",
    "\n",
    "cum = train_df.groupby(\"user_id\")[\"lag\"].agg([\"cumsum\", \"cumcount\"])\n",
    "train_df[\"user_correctness\"] = cum[\"cumsum\"] / cum[\"cumcount\"]\n",
    "train_df[\"user_correct_cumsum\"] = cum[\"cumsum\"]\n",
    "train_df[\"user_correct_cumcount\"] = cum[\"cumcount\"]\n",
    "train_df.drop(columns=[\"lag\"], inplace=True)\n",
    "\n",
    "# train_df['user_correctness'].fillna(1, inplace=True)\n",
    "train_df[\"user_correct_cumsum\"].fillna(0, inplace=True)\n",
    "# train_df['user_correct_cumcount'].fillna(0, inplace=True)\n",
    "train_df.user_correctness = train_df.user_correctness.astype(\"float16\")\n",
    "train_df.user_correct_cumcount = train_df.user_correct_cumcount.astype(\"int16\")\n",
    "train_df.user_correct_cumsum = train_df.user_correct_cumsum.astype(\"int16\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.prior_question_had_explanation = (\n",
    "    train_df.prior_question_had_explanation.astype(\"int8\")\n",
    ")\n",
    "train_df[\"lag\"] = train_df.groupby(\"user_id\")[\"prior_question_had_explanation\"].shift()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cum = train_df.groupby(\"user_id\")[\"lag\"].agg([\"cumsum\", \"cumcount\"])\n",
    "train_df[\"explanation_mean\"] = cum[\"cumsum\"] / cum[\"cumcount\"]\n",
    "train_df[\"explanation_cumsum\"] = cum[\"cumsum\"]\n",
    "train_df.drop(columns=[\"lag\"], inplace=True)\n",
    "train_df[\"explanation_mean\"].fillna(0, inplace=True)\n",
    "train_df[\"explanation_cumsum\"].fillna(0, inplace=True)\n",
    "train_df.explanation_mean = train_df.explanation_mean.astype(\"float16\")\n",
    "train_df.explanation_cumsum = train_df.explanation_cumsum.astype(\"int16\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del cum\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"attempt_no\"] = 1\n",
    "train_df.attempt_no = train_df.attempt_no.astype(\"int8\")\n",
    "train_df[\"attempt_no\"] = (\n",
    "    train_df[[\"user_id\", \"content_id\", \"attempt_no\"]]\n",
    "    .groupby([\"user_id\", \"content_id\"])[\"attempt_no\"]\n",
    "    .cumsum()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "explanation_agg = train_df.groupby(\"user_id\")[\"prior_question_had_explanation\"].agg(\n",
    "    [\"sum\", \"count\"]\n",
    ")\n",
    "explanation_agg = explanation_agg.astype(\"int16\")\n",
    "# train_df.drop(columns=['prior_question_had_explanation'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_agg = train_df.groupby(\"user_id\")[target].agg([\"sum\", \"count\"])\n",
    "content_agg = train_df.groupby(\"content_id\")[target].agg([\"sum\", \"count\", \"var\"])\n",
    "task_container_agg = train_df.groupby(\"task_container_id\")[target].agg(\n",
    "    [\"sum\", \"count\", \"var\"]\n",
    ")\n",
    "\n",
    "# prior_question_elapsed_time_agg = train_df.groupby('user_id')['prior_question_elapsed_time'].agg(['sum', 'count'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_agg = user_agg.astype(\"int16\")\n",
    "content_agg = content_agg.astype(\"float32\")\n",
    "task_container_agg = task_container_agg.astype(\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attempt_no_agg = train_df.groupby([\"user_id\", \"content_id\"])[\"attempt_no\"].agg([\"sum\"])\n",
    "attempt_no_agg = attempt_no_agg.astype(\"int8\")\n",
    "# attempt_series = train_df[['user_id', 'content_id','attempt_no']].groupby(['user_id','content_id'])['attempt_no'].max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"content_count\"] = (\n",
    "    train_df[\"content_id\"].map(content_agg[\"count\"]).astype(\"int32\")\n",
    ")\n",
    "train_df[\"content_sum\"] = train_df[\"content_id\"].map(content_agg[\"sum\"]).astype(\"int32\")\n",
    "train_df[\"content_correctness\"] = train_df[\"content_id\"].map(\n",
    "    content_agg[\"sum\"] / content_agg[\"count\"]\n",
    ")\n",
    "train_df.content_correctness = train_df.content_correctness.astype(\"float16\")\n",
    "train_df[\"task_container_sum\"] = (\n",
    "    train_df[\"task_container_id\"].map(task_container_agg[\"sum\"]).astype(\"int32\")\n",
    ")\n",
    "train_df[\"task_container_std\"] = (\n",
    "    train_df[\"task_container_id\"].map(task_container_agg[\"var\"]).astype(\"float16\")\n",
    ")\n",
    "train_df[\"task_container_correctness\"] = train_df[\"task_container_id\"].map(\n",
    "    task_container_agg[\"sum\"] / task_container_agg[\"count\"]\n",
    ")\n",
    "train_df.task_container_correctness = train_df.task_container_correctness.astype(\n",
    "    \"float16\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv(\n",
    "    \"../input/riiid-test-answer-prediction/questions.csv\",\n",
    "    usecols=[0, 1, 3, 4],\n",
    "    dtype={\"question_id\": \"int16\", \"bundle_id\": \"int16\", \"part\": \"int8\", \"tags\": \"str\"},\n",
    ")\n",
    "questions_df[\"part_bundle_id\"] = (\n",
    "    questions_df[\"part\"] * 100000 + questions_df[\"bundle_id\"]\n",
    ")\n",
    "questions_df.part_bundle_id = questions_df.part_bundle_id.astype(\"int32\")\n",
    "tag = questions_df[\"tags\"].str.split(\" \", n=10, expand=True)\n",
    "tag.columns = [\"tags1\", \"tags2\", \"tags3\", \"tags4\", \"tags5\", \"tags6\"]\n",
    "#\n",
    "\n",
    "tag.fillna(0, inplace=True)\n",
    "tag = tag.astype(\"int16\")\n",
    "questions_df = pd.concat([questions_df, tag], axis=1).drop([\"tags\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions_df.rename(columns={\"question_id\": \"content_id\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions_df[\"content_correctness\"] = questions_df[\"content_id\"].map(\n",
    "    content_agg[\"sum\"] / content_agg[\"count\"]\n",
    ")\n",
    "questions_df.content_correctness = questions_df.content_correctness.astype(\"float16\")\n",
    "questions_df[\"content_correctness_std\"] = questions_df[\"content_id\"].map(\n",
    "    content_agg[\"var\"]\n",
    ")\n",
    "questions_df.content_correctness_std = questions_df.content_correctness_std.astype(\n",
    "    \"float16\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_agg = questions_df.groupby(\"part\")[\"content_correctness\"].agg([\"mean\", \"var\"])\n",
    "questions_df[\"part_correctness_mean\"] = questions_df[\"part\"].map(part_agg[\"mean\"])\n",
    "questions_df[\"part_correctness_std\"] = questions_df[\"part\"].map(part_agg[\"var\"])\n",
    "questions_df.part_correctness_mean = questions_df.part_correctness_mean.astype(\n",
    "    \"float16\"\n",
    ")\n",
    "questions_df.part_correctness_std = questions_df.part_correctness_std.astype(\"float16\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bundle_agg = questions_df.groupby(\"bundle_id\")[\"content_correctness\"].agg([\"mean\"])\n",
    "questions_df[\"bundle_correctness\"] = questions_df[\"bundle_id\"].map(bundle_agg[\"mean\"])\n",
    "questions_df.bundle_correctness = questions_df.bundle_correctness.astype(\"float16\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tags1_agg = questions_df.groupby(\"tags1\")[\"content_correctness\"].agg([\"mean\", \"var\"])\n",
    "questions_df[\"tags1_correctness_mean\"] = questions_df[\"tags1\"].map(tags1_agg[\"mean\"])\n",
    "questions_df[\"tags1_correctness_std\"] = questions_df[\"tags1\"].map(tags1_agg[\"var\"])\n",
    "questions_df.tags1_correctness_mean = questions_df.tags1_correctness_mean.astype(\n",
    "    \"float16\"\n",
    ")\n",
    "questions_df.tags1_correctness_std = questions_df.tags1_correctness_std.astype(\n",
    "    \"float16\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions_df.drop(columns=[\"content_correctness\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del bundle_agg\n",
    "del part_agg\n",
    "del tags1_agg\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_columns\",500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# questions_df.drop(columns=['tags4','tags5','tags6'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"user_correctness\"].fillna(1, inplace=True)\n",
    "train_df[\"attempt_no\"].fillna(1, inplace=True)\n",
    "#\n",
    "train_df.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SAKT Part I"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HDKIM\n",
    "\n",
    "# this is the max lenght of the sequence of the sakt model.\n",
    "MAX_SEQ = 160\n",
    "\n",
    "skills = train_df[\"content_id\"].unique()\n",
    "n_skill = len(skills)\n",
    "print(\"number skills\", len(skills))\n",
    "\n",
    "group = (\n",
    "    train_df[[\"user_id\", \"content_id\", \"answered_correctly\"]]\n",
    "    .groupby(\"user_id\")\n",
    "    .apply(lambda r: (r[\"content_id\"].values, r[\"answered_correctly\"].values))\n",
    ")\n",
    "\n",
    "for user_id in group.index:\n",
    "    q, qa = group[user_id]\n",
    "    if len(q) > MAX_SEQ:\n",
    "        group[user_id] = (q[-MAX_SEQ:], qa[-MAX_SEQ:])\n",
    "\n",
    "pickle.dump(group, open(\"group.pkl\", \"wb\"))\n",
    "del group\n",
    "gc.collect()\n",
    "\n",
    "# HDKIMHDKIM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = [\n",
    "    #   'user_id',\n",
    "    # HDKIM    'timestamp',\n",
    "    \"lagtime\",\n",
    "    \"lagtime_mean\",\n",
    "    # 'content_id',\n",
    "    # 'task_container_id',\n",
    "    \"user_lecture_cumsum\",  # X\n",
    "    \"user_lecture_lv\",\n",
    "    \"prior_question_elapsed_time\",\n",
    "    \"delta_prior_question_elapsed_time\",\n",
    "    \"user_correctness\",\n",
    "    \"user_correct_cumcount\",  # X\n",
    "    \"user_correct_cumsum\",  # X\n",
    "    \"content_correctness\",\n",
    "    # 'content_correctness_std',\n",
    "    \"content_count\",\n",
    "    \"content_sum\",  # X\n",
    "    \"task_container_correctness\",\n",
    "    # 'task_container_std',\n",
    "    # 'task_container_sum',\n",
    "    \"bundle_correctness\",\n",
    "    \"attempt_no\",\n",
    "    \"part\",\n",
    "    \"part_correctness_mean\",\n",
    "    # 'part_correctness_std',\n",
    "    \"tags1\",\n",
    "    \"tags1_correctness_mean\",\n",
    "    #  'tags1_correctness_std',\n",
    "    # HDKIM    'tags2',\n",
    "    # HDKIM    'tags3',\n",
    "    # HDKIM    'tags4',\n",
    "    # HDKIM    'tags5',\n",
    "    # HDKIM    'tags6',\n",
    "    \"bundle_id\",\n",
    "    #  'part_bundle_id',\n",
    "    \"explanation_mean\",\n",
    "    \"explanation_cumsum\",\n",
    "    \"prior_question_had_explanation\",\n",
    "    #     'part_1',\n",
    "    #     'part_2',\n",
    "    #     'part_3',\n",
    "    #     'part_4',\n",
    "    #     'part_5',\n",
    "    #     'part_6',\n",
    "    #     'part_7',\n",
    "    #     'type_of_concept',\n",
    "    #     'type_of_intention',\n",
    "    #     'type_of_solving_question',\n",
    "    #     'type_of_starter'\n",
    "]\n",
    "categorical_columns = [\n",
    "    #   'user_id',\n",
    "    #  'content_id',\n",
    "    # 'task_container_id',\n",
    "    \"part\",\n",
    "    \"tags1\",\n",
    "    # HDKIM    'tags2',\n",
    "    # HDKIM    'tags3',\n",
    "    # HDKIM    'tags4',\n",
    "    # HDKIM    'tags5',\n",
    "    # HDKIM    'tags6',\n",
    "    \"bundle_id\",\n",
    "    # 'part_bundle_id',\n",
    "    \"prior_question_had_explanation\",\n",
    "    #     'part_1',\n",
    "    #     'part_2',\n",
    "    #     'part_3',\n",
    "    #     'part_4',\n",
    "    #     'part_5',\n",
    "    #     'part_6',\n",
    "    #     'part_7',\n",
    "    #     'type_of_concept',\n",
    "    #     'type_of_intention',\n",
    "    #     'type_of_solving_question',\n",
    "    #     'type_of_starter'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flag_lgbm = True\n",
    "clfs = list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the parameters with Optuna from [this Notebook](https://github.com/satorushibata0627/Publishment/blob/main/Kaggle_Python3_LightGBM_on_GPU_with_Feature_Engineering_Optuna_and_Visualization.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = pd.read_pickle(\n",
    "    \"../input/the-best-of-all-parameters-on-lightgbm/The_best_of_all_parameters_on_LightGBM.pickle\"\n",
    ")\n",
    "print(\"Optimized parameters with Optuna:\")\n",
    "print(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trains = list()\n",
    "valids = list()\n",
    "num = 1\n",
    "for i in range(0, num):\n",
    "\n",
    "    train_df_clf = train_df.sample(n=20000 * 1000, random_state=SEED)\n",
    "    print(\"sample end\")\n",
    "\n",
    "    del train_df\n",
    "\n",
    "    users = train_df_clf[\"user_id\"].drop_duplicates()\n",
    "\n",
    "    users = users.sample(frac=0.025, random_state=SEED)\n",
    "    users_df = pd.DataFrame()\n",
    "    users_df[\"user_id\"] = users.values\n",
    "\n",
    "    valid_df_newuser = pd.merge(\n",
    "        train_df_clf, users_df, on=[\"user_id\"], how=\"inner\", right_index=True\n",
    "    )\n",
    "    del users_df\n",
    "    del users\n",
    "    gc.collect()\n",
    "    #\n",
    "    train_df_clf.drop(valid_df_newuser.index, inplace=True)\n",
    "\n",
    "    train_df_clf = pd.merge(\n",
    "        train_df_clf, questions_df, on=\"content_id\", how=\"left\", right_index=True\n",
    "    )  #\n",
    "    valid_df_newuser = pd.merge(\n",
    "        valid_df_newuser, questions_df, on=\"content_id\", how=\"left\", right_index=True\n",
    "    )  #\n",
    "\n",
    "    valid_df = train_df_clf.sample(frac=0.09, random_state=SEED)\n",
    "    train_df_clf.drop(valid_df.index, inplace=True)\n",
    "\n",
    "    valid_df = valid_df.append(valid_df_newuser)\n",
    "    del valid_df_newuser\n",
    "    gc.collect()\n",
    "    #\n",
    "\n",
    "    trains.append(train_df_clf)\n",
    "    valids.append(valid_df)\n",
    "    print(\"valid_df lengthÃ¯Â¼Å¡\", len(valid_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del train_df_clf\n",
    "del valid_df\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Refer to [Riiid model LGBM](https://www.kaggle.com/ragnar123/riiid-model-lgbm/notebook) for following:\n",
    "- num_boost_round\n",
    "- early_stopping_rounds\n",
    "- verbose_eval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(0, num):\n",
    "\n",
    "    #\n",
    "    tr_data = lgb.Dataset(trains[i][features], label=trains[i][target])\n",
    "    va_data = lgb.Dataset(\n",
    "        valids[i][features], label=valids[i][target], reference=tr_data\n",
    "    )\n",
    "\n",
    "    #     del train_df_clf\n",
    "    #     del valid_df\n",
    "    #     gc.collect()\n",
    "    del trains\n",
    "    del valids\n",
    "    gc.collect()\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        tr_data,\n",
    "        #         train_df[features],\n",
    "        #         train_df[target],\n",
    "        num_boost_round=10000,\n",
    "        # valid_sets=[(train_df[features],train_df[target]), (valid_df[features],valid_df[target])],\n",
    "        valid_sets=[tr_data, va_data],\n",
    "        early_stopping_rounds=50,\n",
    "        feature_name=features,\n",
    "        categorical_feature=categorical_columns,\n",
    "        verbose_eval=50,\n",
    "    )\n",
    "    clfs.append(model)\n",
    "\n",
    "    # Clean the memory\n",
    "    del tr_data\n",
    "    del va_data\n",
    "    gc.collect()\n",
    "#\n",
    "# del trains\n",
    "# del valids\n",
    "# gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_sum_dict = user_agg[\"sum\"].astype(\"int16\").to_dict(defaultdict(int))\n",
    "user_count_dict = user_agg[\"count\"].astype(\"int16\").to_dict(defaultdict(int))\n",
    "content_sum_dict = content_agg[\"sum\"].astype(\"int32\").to_dict(defaultdict(int))\n",
    "content_count_dict = content_agg[\"count\"].astype(\"int32\").to_dict(defaultdict(int))\n",
    "\n",
    "del user_agg\n",
    "del content_agg\n",
    "gc.collect()\n",
    "\n",
    "task_container_sum_dict = (\n",
    "    task_container_agg[\"sum\"].astype(\"int32\").to_dict(defaultdict(int))\n",
    ")\n",
    "task_container_count_dict = (\n",
    "    task_container_agg[\"count\"].astype(\"int32\").to_dict(defaultdict(int))\n",
    ")\n",
    "task_container_std_dict = (\n",
    "    task_container_agg[\"var\"].astype(\"float16\").to_dict(defaultdict(int))\n",
    ")\n",
    "\n",
    "explanation_sum_dict = explanation_agg[\"sum\"].astype(\"int16\").to_dict(defaultdict(int))\n",
    "explanation_count_dict = (\n",
    "    explanation_agg[\"count\"].astype(\"int16\").to_dict(defaultdict(int))\n",
    ")\n",
    "del task_container_agg\n",
    "del explanation_agg\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_lecture_sum_dict = (\n",
    "    user_lecture_agg[\"sum\"].astype(\"int16\").to_dict(defaultdict(int))\n",
    ")\n",
    "user_lecture_count_dict = (\n",
    "    user_lecture_agg[\"count\"].astype(\"int16\").to_dict(defaultdict(int))\n",
    ")\n",
    "\n",
    "lagtime_mean_dict = lagtime_agg[\"mean\"].astype(\"int32\").to_dict(defaultdict(int))\n",
    "# del prior_question_elapsed_time_agg\n",
    "del user_lecture_agg\n",
    "del lagtime_agg\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attempt_no_agg = attempt_no_agg[attempt_no_agg[\"sum\"] > 1]\n",
    "attempt_no_sum_dict = attempt_no_agg[\"sum\"].to_dict(defaultdict(int))\n",
    "\n",
    "del attempt_no_agg\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_timestamp_u_dict = max_timestamp_u.set_index(\"user_id\").to_dict()\n",
    "user_prior_question_elapsed_time_dict = user_prior_question_elapsed_time.set_index(\n",
    "    \"user_id\"\n",
    ").to_dict()\n",
    "# del question_elapsed_time_agg\n",
    "del max_timestamp_u\n",
    "del user_prior_question_elapsed_time\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(max_timestamp_u_dict[\"max_time_stamp\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_max_attempt(user_id, content_id):\n",
    "    k = (user_id, content_id)\n",
    "\n",
    "    if k in attempt_no_sum_dict.keys():\n",
    "        attempt_no_sum_dict[k] += 1\n",
    "        return attempt_no_sum_dict[k]\n",
    "\n",
    "    attempt_no_sum_dict[k] = 1\n",
    "    return attempt_no_sum_dict[k]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(psutil.virtual_memory().percent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SAKT Part II"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HDKIM SAKT\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, state_size=200):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.lr1 = nn.Linear(state_size, state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr2 = nn.Linear(state_size, state_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "def future_mask(seq_length):\n",
    "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype(\"bool\")\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "\n",
    "class SAKTModel(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=MAX_SEQ, embed_dim=128):  # HDKIM 100\n",
    "        super(SAKTModel, self).__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(2 * n_skill + 1, embed_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_seq - 1, embed_dim)\n",
    "        self.e_embedding = nn.Embedding(n_skill + 1, embed_dim)\n",
    "\n",
    "        self.multi_att = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim, num_heads=8, dropout=0.2\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.ffn = FFN(embed_dim)\n",
    "        self.pred = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x, question_ids):\n",
    "        device = x.device\n",
    "        x = self.embedding(x)\n",
    "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
    "\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        x = x + pos_x\n",
    "\n",
    "        e = self.e_embedding(question_ids)\n",
    "\n",
    "        x = x.permute(1, 0, 2)  # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        e = e.permute(1, 0, 2)\n",
    "        att_mask = future_mask(x.size(0)).to(device)\n",
    "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
    "        att_output = self.layer_normal(att_output + e)\n",
    "        att_output = att_output.permute(\n",
    "            1, 0, 2\n",
    "        )  # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
    "\n",
    "        x = self.ffn(att_output)\n",
    "        x = self.layer_normal(x + att_output)\n",
    "        x = self.pred(x)\n",
    "\n",
    "        return x.squeeze(-1), att_weight\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, skills, max_seq=MAX_SEQ):  # HDKIM 100\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.samples = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df = test_df\n",
    "        self.skills = skills\n",
    "        self.n_skill = len(skills)\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "\n",
    "        user_id = test_info[\"user_id\"]\n",
    "        target_id = test_info[\"content_id\"]\n",
    "\n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "\n",
    "        if user_id in self.samples.index:\n",
    "            q_, qa_ = self.samples[user_id]\n",
    "\n",
    "            seq_len = len(q_)\n",
    "\n",
    "            if seq_len >= self.max_seq:\n",
    "                q = q_[-self.max_seq :]\n",
    "                qa = qa_[-self.max_seq :]\n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_\n",
    "\n",
    "        x = np.zeros(self.max_seq - 1, dtype=int)\n",
    "        x = q[1:].copy()\n",
    "        x += (qa[1:] == 1) * self.n_skill\n",
    "\n",
    "        questions = np.append(q[2:], [target_id])\n",
    "\n",
    "        return x, questions\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAKT_model = SAKTModel(n_skill, embed_dim=128)\n",
    "\n",
    "try:\n",
    "    SAKT_model.load_state_dict(\n",
    "        torch.load(\"../input/sakt-with-randomization-state-updates/SAKT-HDKIM.pt\")\n",
    "    )\n",
    "except:\n",
    "    SAKT_model.load_state_dict(\n",
    "        torch.load(\n",
    "            \"../input/sakt-with-randomization-state-updates/SAKT-HDKIM.pt\",\n",
    "            map_location=\"cpu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "SAKT_model.to(device)\n",
    "SAKT_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "group = pickle.load(open(\"group.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(psutil.virtual_memory().percent)\n",
    "# HDKIMHDKIM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()\n",
    "prior_test_df = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    if (prior_test_df is not None) & (psutil.virtual_memory().percent < 90):\n",
    "        print(psutil.virtual_memory().percent)\n",
    "        prior_test_df[target] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
    "        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        prior_test_df[\"prior_question_had_explanation\"].fillna(False, inplace=True)\n",
    "        prior_test_df.prior_question_had_explanation = (\n",
    "            prior_test_df.prior_question_had_explanation.astype(\"int8\")\n",
    "        )\n",
    "\n",
    "        # HDKIM SAKT State Update\n",
    "        prev_group = (\n",
    "            prior_test_df[[\"user_id\", \"content_id\", \"answered_correctly\"]]\n",
    "            .groupby(\"user_id\")\n",
    "            .apply(lambda r: (r[\"content_id\"].values, r[\"answered_correctly\"].values))\n",
    "        )\n",
    "        for prev_user_id in prev_group.index:\n",
    "            prev_group_content = prev_group[prev_user_id][0]\n",
    "            prev_group_ac = prev_group[prev_user_id][1]\n",
    "            if prev_user_id in group.index:\n",
    "                group[prev_user_id] = (\n",
    "                    np.append(group[prev_user_id][0], prev_group_content),\n",
    "                    np.append(group[prev_user_id][1], prev_group_ac),\n",
    "                )\n",
    "            else:\n",
    "                group[prev_user_id] = (prev_group_content, prev_group_ac)\n",
    "            if len(group[prev_user_id][0]) > MAX_SEQ:\n",
    "                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n",
    "                new_group_ac = group[prev_user_id][1][-MAX_SEQ:]\n",
    "                group[prev_user_id] = (new_group_content, new_group_ac)\n",
    "\n",
    "        # HDKIMHDKIM\n",
    "\n",
    "        user_ids = prior_test_df[\"user_id\"].values\n",
    "        content_ids = prior_test_df[\"content_id\"].values\n",
    "        task_container_ids = prior_test_df[\"task_container_id\"].values\n",
    "        prior_question_had_explanations = prior_test_df[\n",
    "            \"prior_question_had_explanation\"\n",
    "        ].values\n",
    "        targets = prior_test_df[target].values\n",
    "\n",
    "        for (\n",
    "            user_id,\n",
    "            content_id,\n",
    "            prior_question_had_explanation,\n",
    "            task_container_id,\n",
    "            answered_correctly,\n",
    "        ) in zip(\n",
    "            user_ids,\n",
    "            content_ids,\n",
    "            prior_question_had_explanations,\n",
    "            task_container_ids,\n",
    "            targets,\n",
    "        ):\n",
    "            user_sum_dict[user_id] += answered_correctly\n",
    "            user_count_dict[user_id] += 1\n",
    "            explanation_sum_dict[user_id] += prior_question_had_explanation\n",
    "            explanation_count_dict[user_id] += 1\n",
    "\n",
    "    prior_test_df = test_df.copy()\n",
    "    lecture_test_df = test_df[test_df[\"content_type_id\"] == 1].reset_index(drop=True)\n",
    "\n",
    "    for i, (user_id, content_type_id, content_id) in enumerate(\n",
    "        zip(\n",
    "            lecture_test_df[\"user_id\"].values,\n",
    "            lecture_test_df[\"content_type_id\"].values,\n",
    "            lecture_test_df[\"content_id\"].values,\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        user_lecture_sum_dict[user_id] += content_type_id\n",
    "        user_lecture_count_dict[user_id] += 1\n",
    "        #\n",
    "        if (\n",
    "            len(user_lecture_stats_part[user_lecture_stats_part.user_id == user_id])\n",
    "            == 0\n",
    "        ):\n",
    "            user_lecture_stats_part = user_lecture_stats_part.append(\n",
    "                [{\"user_id\": user_id}], ignore_index=True\n",
    "            )\n",
    "            user_lecture_stats_part.fillna(0, inplace=True)\n",
    "            user_lecture_stats_part.loc[\n",
    "                user_lecture_stats_part.user_id == user_id,\n",
    "                part_lectures_columns + types_of_lectures_columns,\n",
    "            ] += lectures_df[lectures_df.lecture_id == content_id][\n",
    "                part_lectures_columns + types_of_lectures_columns\n",
    "            ].values\n",
    "        else:\n",
    "            user_lecture_stats_part.loc[\n",
    "                user_lecture_stats_part.user_id == user_id,\n",
    "                part_lectures_columns + types_of_lectures_columns,\n",
    "            ] += lectures_df[lectures_df.lecture_id == content_id][\n",
    "                part_lectures_columns + types_of_lectures_columns\n",
    "            ].values\n",
    "\n",
    "    test_df = test_df[test_df[\"content_type_id\"] == 0].reset_index(drop=True)\n",
    "\n",
    "    # HDKIM SAKT\n",
    "    test_dataset = TestDataset(group, test_df, skills)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=51200, shuffle=False)\n",
    "\n",
    "    SAKT_outs = []\n",
    "\n",
    "    for item in test_dataloader:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, att_weight = SAKT_model(x, target_id)\n",
    "\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[:, -1]\n",
    "        SAKT_outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "    # HDKIMHDKIM\n",
    "\n",
    "    test_df[\"prior_question_had_explanation\"].fillna(False, inplace=True)\n",
    "    test_df.prior_question_had_explanation = (\n",
    "        test_df.prior_question_had_explanation.astype(\"int8\")\n",
    "    )\n",
    "    test_df[\"prior_question_elapsed_time\"].fillna(\n",
    "        prior_question_elapsed_time_mean, inplace=True\n",
    "    )\n",
    "\n",
    "    user_lecture_sum = np.zeros(len(test_df), dtype=np.int16)\n",
    "    user_lecture_count = np.zeros(len(test_df), dtype=np.int16)\n",
    "\n",
    "    user_sum = np.zeros(len(test_df), dtype=np.int16)\n",
    "    user_count = np.zeros(len(test_df), dtype=np.int16)\n",
    "    content_sum = np.zeros(len(test_df), dtype=np.int32)\n",
    "    content_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    task_container_sum = np.zeros(len(test_df), dtype=np.int32)\n",
    "    task_container_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    task_container_std = np.zeros(len(test_df), dtype=np.float16)\n",
    "    content_task_mean = np.zeros(len(test_df), dtype=np.float16)\n",
    "    explanation_sum = np.zeros(len(test_df), dtype=np.int32)\n",
    "    explanation_count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    delta_prior_question_elapsed_time = np.zeros(len(test_df), dtype=np.int32)\n",
    "\n",
    "    attempt_no_count = np.zeros(len(test_df), dtype=np.int16)\n",
    "    lagtime = np.zeros(len(test_df), dtype=np.int32)\n",
    "    lagtime_mean = np.zeros(len(test_df), dtype=np.int32)\n",
    "\n",
    "    for i, (\n",
    "        user_id,\n",
    "        prior_question_had_explanation,\n",
    "        content_type_id,\n",
    "        prior_question_elapsed_time,\n",
    "        timestamp,\n",
    "        content_id,\n",
    "        task_container_id,\n",
    "    ) in enumerate(\n",
    "        zip(\n",
    "            test_df[\"user_id\"].values,\n",
    "            test_df[\"prior_question_had_explanation\"].values,\n",
    "            test_df[\"content_type_id\"].values,\n",
    "            test_df[\"prior_question_elapsed_time\"].values,\n",
    "            test_df[\"timestamp\"].values,\n",
    "            test_df[\"content_id\"].values,\n",
    "            test_df[\"task_container_id\"].values,\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        user_lecture_sum_dict[user_id] += content_type_id\n",
    "        user_lecture_count_dict[user_id] += 1\n",
    "\n",
    "        user_lecture_sum[i] = user_lecture_sum_dict[user_id]\n",
    "        user_lecture_count[i] = user_lecture_count_dict[user_id]\n",
    "\n",
    "        user_sum[i] = user_sum_dict[user_id]\n",
    "        user_count[i] = user_count_dict[user_id]\n",
    "        content_sum[i] = content_sum_dict[content_id]\n",
    "        content_count[i] = content_count_dict[content_id]\n",
    "        task_container_sum[i] = task_container_sum_dict[task_container_id]\n",
    "        task_container_count[i] = task_container_count_dict[task_container_id]\n",
    "        task_container_std[i] = task_container_std_dict[task_container_id]\n",
    "\n",
    "        explanation_sum[i] = explanation_sum_dict[user_id]\n",
    "        explanation_count[i] = explanation_count_dict[user_id]\n",
    "\n",
    "        if user_id in max_timestamp_u_dict[\"max_time_stamp\"].keys():\n",
    "            lagtime[i] = timestamp - max_timestamp_u_dict[\"max_time_stamp\"][user_id]\n",
    "            max_timestamp_u_dict[\"max_time_stamp\"][user_id] = timestamp\n",
    "            lagtime_mean[i] = (lagtime_mean_dict[user_id] + lagtime[i]) / 2\n",
    "        else:\n",
    "            lagtime[i] = 0\n",
    "            max_timestamp_u_dict[\"max_time_stamp\"].update({user_id: timestamp})\n",
    "            lagtime_mean_dict.update({user_id: timestamp})\n",
    "            lagtime_mean[i] = (lagtime_mean_dict[user_id] + lagtime[i]) / 2\n",
    "\n",
    "        if (\n",
    "            user_id\n",
    "            in user_prior_question_elapsed_time_dict[\n",
    "                \"prior_question_elapsed_time\"\n",
    "            ].keys()\n",
    "        ):\n",
    "            delta_prior_question_elapsed_time[i] = (\n",
    "                prior_question_elapsed_time\n",
    "                - user_prior_question_elapsed_time_dict[\"prior_question_elapsed_time\"][\n",
    "                    user_id\n",
    "                ]\n",
    "            )\n",
    "            user_prior_question_elapsed_time_dict[\"prior_question_elapsed_time\"][\n",
    "                user_id\n",
    "            ] = prior_question_elapsed_time\n",
    "        else:\n",
    "            delta_prior_question_elapsed_time[i] = 0\n",
    "            user_prior_question_elapsed_time_dict[\"prior_question_elapsed_time\"].update(\n",
    "                {user_id: prior_question_elapsed_time}\n",
    "            )\n",
    "\n",
    "    #\n",
    "    # test_df = pd.merge(test_df, questions_df, on='content_id', how='left',right_index=True)\n",
    "    # test_df = pd.concat([test_df.reset_index(drop=True), questions_df.reindex(test_df['content_id'].values).reset_index(drop=True)], axis=1)\n",
    "    test_df = test_df.merge(\n",
    "        questions_df.loc[questions_df.index.isin(test_df[\"content_id\"])],\n",
    "        how=\"left\",\n",
    "        on=\"content_id\",\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # test_df = pd.merge(test_df, user_lecture_stats_part, on=['user_id'], how=\"left\",right_index=True)\n",
    "    # test_df = pd.concat([test_df.reset_index(drop=True), user_lecture_stats_part.reindex(test_df['user_id'].values).reset_index(drop=True)], axis=1)\n",
    "    #     test_df=test_df.merge(user_lecture_stats_part.loc[user_lecture_stats_part.index.isin(test_df['user_id'])],\n",
    "    #                   how='left', on='user_id', right_index=True)\n",
    "\n",
    "    test_df[\"user_lecture_lv\"] = user_lecture_sum / user_lecture_count\n",
    "    test_df[\"user_lecture_cumsum\"] = user_lecture_sum\n",
    "    test_df[\"user_correctness\"] = user_sum / user_count\n",
    "    test_df[\"user_correct_cumcount\"] = user_count\n",
    "    test_df[\"user_correct_cumsum\"] = user_sum\n",
    "    #\n",
    "    test_df[\"content_correctness\"] = content_sum / content_count\n",
    "    test_df[\"content_count\"] = content_count\n",
    "    test_df[\"content_sum\"] = content_sum\n",
    "\n",
    "    test_df[\"task_container_correctness\"] = task_container_sum / task_container_count\n",
    "    test_df[\"task_container_sum\"] = task_container_sum\n",
    "    test_df[\"task_container_std\"] = task_container_std\n",
    "    # test_df['content_task_mean'] = content_task_mean\n",
    "\n",
    "    test_df[\"explanation_mean\"] = explanation_sum / explanation_count\n",
    "    test_df[\"explanation_cumsum\"] = explanation_sum\n",
    "\n",
    "    #\n",
    "    test_df[\"delta_prior_question_elapsed_time\"] = delta_prior_question_elapsed_time\n",
    "\n",
    "    test_df[\"attempt_no\"] = test_df[[\"user_id\", \"content_id\"]].apply(\n",
    "        lambda row: get_max_attempt(row[\"user_id\"], row[\"content_id\"]), axis=1\n",
    "    )\n",
    "    test_df[\"lagtime\"] = lagtime\n",
    "    test_df[\"lagtime_mean\"] = lagtime_mean\n",
    "\n",
    "    test_df[\"user_correctness\"].fillna(1, inplace=True)\n",
    "    test_df[\"attempt_no\"].fillna(1, inplace=True)\n",
    "    #\n",
    "    test_df.fillna(0, inplace=True)\n",
    "\n",
    "    test_df[\"timestamp\"] = test_df[\"timestamp\"] / (1000 * 3600)\n",
    "    test_df.timestamp = test_df.timestamp.astype(\"int16\")\n",
    "\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "    for i, model in enumerate(clfs, 1):\n",
    "        test_preds = model.predict(\n",
    "            test_df[features], num_iteration=model.best_iteration\n",
    "        )\n",
    "        sub_preds += test_preds\n",
    "\n",
    "    # HDKIM\n",
    "    # test_df[target] = sub_preds / len(clfs) #HDKIM\n",
    "\n",
    "    lgbm_final = sub_preds / len(clfs)\n",
    "    test_df[target] = np.array(SAKT_outs) * 0.5 + lgbm_final * 0.5\n",
    "    # HDKIMHDKIM\n",
    "\n",
    "    # Submission\n",
    "    env.predict(test_df[[\"row_id\", target]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_df\n",
    "pickle.dump(test_df, open(\"test_df.pickle\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model\n",
    "model.save_model(\"model.txt\")\n",
    "print(\"Save the best of model.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Parameters\n",
    "pickle.dump(params, open(\"The_best_of_all_parameters_on_LightGBM.pickle\", \"wb\"))\n",
    "print(\"Save the best of parameters.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization & Empirical analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target = \"answered_correctly\"\n",
    "y_true = pd.read_csv(\n",
    "    \"../input/riiid-test-answer-prediction/train.csv\", usecols=[target]\n",
    ")\n",
    "print(\"Length of y_true =\", len(y_true))\n",
    "y_pred = pd.read_csv(\"./submission.csv\", usecols=[target])\n",
    "print(\"Length of y_pred =\", len(y_pred))\n",
    "test_df = pd.read_pickle(\"./test_df.pickle\")\n",
    "print(\"Length of test_df =\", len(test_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = pd.read_pickle(\"./The_best_of_all_parameters_on_LightGBM.pickle\")\n",
    "print(\"Optimized parameters with Optuna:\")\n",
    "print(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = lgb.Booster(model_file=\"./model.txt\", params=params)\n",
    "print(\"Load the model of LightGBM:\")\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = model.feature_name()\n",
    "print(\"Features of LightGBM:\")\n",
    "print(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LightGBM = model.predict(test_df[features])\n",
    "LightGBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run bootstrap\n",
    "y_true_boot = resample(y_true, n_samples=len(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Plot_lgb(model):\n",
    "    plt.figure()\n",
    "    lgb.plot_importance(model, importance_type=\"gain\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    lgb.plot_tree(model, figsize=(30, 50))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Statistical_Significance_Test(y_true_boot, y_pred):\n",
    "    A = np.array(y_true_boot)\n",
    "    B = np.array(y_pred)\n",
    "    # Paired t-test\n",
    "    print(\"Paired t-test:\", stats.ttest_rel(A, B))\n",
    "    # Student's t-test\n",
    "    A_var = np.var(A, ddof=1)  # Unbiased dispersion of A\n",
    "    B_var = np.var(B, ddof=1)  # Unbiased dispersion of B\n",
    "    A_df = len(A) - 1  # Degree of freedom of A\n",
    "    B_df = len(B) - 1  # Degree of freedom of B\n",
    "    f = A_var / B_var  # F ratio value\n",
    "    one_sided_pval1 = stats.f.cdf(f, A_df, B_df)  # One-sided test p-value(1)\n",
    "    one_sided_pval2 = stats.f.sf(f, A_df, B_df)  # One-sided test p-value(2)\n",
    "    two_sided_pval = min(one_sided_pval1, one_sided_pval2) * 2  # Two-sided test p-value\n",
    "    print(\"Student's t-test:\")\n",
    "    print(\"F:       \", round(f, 3))\n",
    "    print(\"p-value: \", round(two_sided_pval, 3))\n",
    "    # Welch's t-test\n",
    "    two_sided_pval = min(one_sided_pval1, one_sided_pval2) * 2  # Two-sided test p-value\n",
    "    print(\"Welch's t-test:\")\n",
    "    print(\"F:       \", round(f, 3))\n",
    "    print(\"p-value: \", round(two_sided_pval, 4))\n",
    "    # Mann-Whitney's U-test\n",
    "    print(\"Mann-Whitney's U-test:\", stats.mannwhitneyu(A, B, alternative=\"two-sided\"))\n",
    "    # Wilcoxon signed rank sum test\n",
    "    print(\"Wilcoxon signed rank sum test:\", stats.wilcoxon(A, B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Histogram\n",
    "def distribution(df):\n",
    "    plt.figure()\n",
    "    sns.distplot(\n",
    "        df,\n",
    "        kde=True,\n",
    "        rug=True,\n",
    "        hist=True,\n",
    "        norm_hist=True,\n",
    "        axlabel=\"Frequency Distribution\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Plot_lgb(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Statistical_Significance_Test(y_true_boot[target], y_pred[target])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Histogram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distribution(y_true_boot[target])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distribution(y_pred[target])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distribution(LightGBM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Done"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Operation completed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I would like to thank the original author, [@Ammar Alhaj Ali](https://www.kaggle.com/ammarnassanalhajali) deeply."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}