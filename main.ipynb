{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7XbmQd3Oazxq"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hiARaMdhazx3",
        "outputId": "18208b26-7f17-42a1-a4ee-8417fcc5de78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "COLAB = True\n",
        "KAGGLE = False\n",
        "DOWNLOAD_DATA = True\n",
        "SAVE_TO_GITHUB = False\n",
        "GIT_REPOSITORY = \"riiid-test-answer-prediction\"\n",
        "FILE_NAME = \"main.ipynb\"\n",
        "\n",
        "if COLAB:\n",
        "    PARENT_DIRECTORY_PATH = \"/content\"\n",
        "    # In case you want to clone in your drive:\n",
        "    # PARENT_DIRECTORY_PATH = \"/content/gdrive/My Drive\"\n",
        "    PROJECT_PATH = PARENT_DIRECTORY_PATH + \"/\" + GIT_REPOSITORY\n",
        "    %cd \"{PARENT_DIRECTORY_PATH}\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rNGqwbShazx3"
      },
      "source": [
        "### Linking personal Google Drive storage with Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "NUEXfwDMazx4"
      },
      "source": [
        "Mounting is the process by which the os makes files and directories of a\n",
        "storage service (google drive) available for the users via the computer's\n",
        "file system. Log in will be required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RJG8SByaazx4",
        "outputId": "712ab443-1df0-4192-9316-a30c2031460d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if COLAB:\n",
        "    %cd /content\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "R7zVbGqzazx4"
      },
      "source": [
        "### Clone GitHub repository to Colab Runtime system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3DvbkhPZazx5",
        "outputId": "8576e1bd-33fa-42c5-cf48-318925a62f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if COLAB:\n",
        "    import json\n",
        "\n",
        "    with open(\"/content/gdrive/My Drive/Git/git.json\", \"r\") as f:\n",
        "        parsed_json = json.load(f)\n",
        "\n",
        "    GIT_USER_NAME = parsed_json[\"GIT_USER_NAME\"]\n",
        "    GIT_TOKEN = parsed_json[\"GIT_TOKEN\"]\n",
        "    GIT_USER_EMAIL = parsed_json[\"GIT_USER_EMAIL\"]\n",
        "\n",
        "    GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{GIT_USER_NAME}/{GIT_REPOSITORY}.git\"\n",
        "\n",
        "    %cd \"{PARENT_DIRECTORY_PATH}\"\n",
        "\n",
        "    !git clone \"{GIT_PATH}\"  # Clone the github repository\n",
        "\n",
        "    %cd \"{PROJECT_PATH}\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'riiid-test-answer-prediction'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 46 (delta 20), reused 35 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n",
            "/content/riiid-test-answer-prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "c_WEm9yeazx5"
      },
      "source": [
        "### Kaggle API Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nQ7Y-LAIazx5"
      },
      "source": [
        "Run the following code to provide the config path to kaggle.json\n",
        "(api credentials)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Nd6XkjYaazx5"
      },
      "source": [
        "if COLAB:\n",
        "    import os\n",
        "\n",
        "    os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "wRy8EiQCazx5"
      },
      "source": [
        "### Download the data using the API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qbttgNE4azx6"
      },
      "source": [
        "Before start downloading the data, make sure u are in a directory outside\n",
        "your Google Drive; otherwise, u will put the data there and you will reach\n",
        "the limit storage easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZLK-DpYEazx6",
        "outputId": "ea5f1782-f32d-4150-fa21-e8eac224df7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if DOWNLOAD_DATA:\n",
        "    !mkdir input\n",
        "    %cd input\n",
        "\n",
        "    !pip install --upgrade kaggle\n",
        "    # Go to kaggle and copy the API Command to download the dataset\n",
        "    # !kaggle competitions download -c {GIT_REPOSITORY}\n",
        "    # Instead of downloading all data, we select specific files.\n",
        "    # !kaggle competitions download {GIT_REPOSITORY} -f train.csv\n",
        "    # !kaggle competitions download {GIT_REPOSITORY} -f test.csv\n",
        "    # !kaggle competitions download {GIT_REPOSITORY} -f sample_submission.csv\n",
        "    !kaggle competitions download -c {GIT_REPOSITORY}\n",
        "\n",
        "    # Unzipping the zip files and deleting the zip files\n",
        "    !unzip \\*.zip  && rm *.zip\n",
        "\n",
        "    # After downloading all data, go back to PROJECT_PATH\n",
        "    %cd ..\n",
        "\n",
        "if KAGGLE:\n",
        "    INPUT_ROOT = f\"../input/{GIT_REPOSITORY}\"\n",
        "else:\n",
        "    INPUT_ROOT = f\"../{GIT_REPOSITORY}/input\"\n",
        "\n",
        "# INPUT_ROOT will be used as follows\n",
        "# train_df = pd.read_csv(f\"{INPUT_ROOT}/train.csv\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/riiid-test-answer-prediction/input\n",
            "Requirement already up-to-date: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading competition.cpython-37m-x86_64-linux-gnu.so to /content/riiid-test-answer-prediction/input\n",
            "  0% 0.00/445k [00:00<?, ?B/s]\n",
            "100% 445k/445k [00:00<00:00, 65.6MB/s]\n",
            "Downloading __init__.py to /content/riiid-test-answer-prediction/input\n",
            "  0% 0.00/59.0 [00:00<?, ?B/s]\n",
            "100% 59.0/59.0 [00:00<00:00, 59.2kB/s]\n",
            "Downloading train.csv.zip to /content/riiid-test-answer-prediction/input\n",
            "100% 1.29G/1.29G [00:26<00:00, 33.0MB/s]\n",
            "100% 1.29G/1.29G [00:26<00:00, 52.7MB/s]\n",
            "Downloading lectures.csv to /content/riiid-test-answer-prediction/input\n",
            "  0% 0.00/9.48k [00:00<?, ?B/s]\n",
            "100% 9.48k/9.48k [00:00<00:00, 8.50MB/s]\n",
            "Downloading example_sample_submission.csv to /content/riiid-test-answer-prediction/input\n",
            "  0% 0.00/971 [00:00<?, ?B/s]\n",
            "100% 971/971 [00:00<00:00, 975kB/s]\n",
            "Downloading example_test.csv to /content/riiid-test-answer-prediction/input\n",
            "  0% 0.00/5.99k [00:00<?, ?B/s]\n",
            "100% 5.99k/5.99k [00:00<00:00, 5.76MB/s]\n",
            "Downloading questions.csv to /content/riiid-test-answer-prediction/input\n",
            "  0% 0.00/289k [00:00<?, ?B/s]\n",
            "100% 289k/289k [00:00<00:00, 95.9MB/s]\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "/content/riiid-test-answer-prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "J6troZvsazx6"
      },
      "source": [
        "### Save changes to GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OTwd7MlMazx6"
      },
      "source": [
        "if SAVE_TO_GITHUB:\n",
        "    !git add {FILE_NAME}\n",
        "    !git config --global user.email {GIT_USER_EMAIL}\n",
        "    !git config --global user.name {GIT_USER_NAME}\n",
        "    !git commit -am \"update {FILE_NAME}\"\n",
        "    !git push"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "q7FFJ9Ofazx7"
      },
      "source": [
        "## \"Improvement of optimized LightGBM with Optuna adding SAKT Model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "skGD2_Rdazx7"
      },
      "source": [
        "### Points:\n",
        "1. This Notebook is based on [Riiid LGBM bagging2 + SAKT =0.781](https://www.kaggle.com/ammarnassanalhajali/riiid-lgbm-bagging2-sakt-0-781);\n",
        "1. I use optimized parameters with Optuna for it;\n",
        "1. This version added visualization and empirical analysis of the submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qb785bQHazx7"
      },
      "source": [
        "### Source Notebooks:\n",
        "1. [SAKT + Riiid LGBM bagging2 LB 0.780](https://www.kaggle.com/leadbest/sakt-riiid-lgbm-bagging2)\n",
        "1. [SAKT with Randomization & State Updates LB0.771](https://www.kaggle.com/leadbest/sakt-with-randomization-state-updates)\n",
        "1. [Riiid! LGBM bagging2 LB0.772](https://www.kaggle.com/zephyrwang666/riiid-lgbm-bagging2)\n",
        "1. [Riiid LGBM bagging2 + SAKT =0.781](https://www.kaggle.com/ammarnassanalhajali/riiid-lgbm-bagging2-sakt-0-781/output?select=group.pkl)\n",
        "1. [Riiid!: Optimized LightGBM with Optuna](https://www.kaggle.com/satorushibata/riiid-optimized-lightgbm-with-optuna?scriptVersionId=50192148)\n",
        "    - The parameters were generated in [LightGBM on GPU with Feature Engineering, Optuna, and, Visualization](https://github.com/satorushibata0627/Publishment/blob/main/Kaggle_Python3_LightGBM_on_GPU_with_Feature_Engineering_Optuna_and_Visualization.ipynb).\n",
        "1. [Fork of Riiid LGBM bagging2.1 471152](https://www.kaggle.com/julianguo/fork-of-riiid-lgbm-bagging2-1-471152)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8UMng7etazx8"
      },
      "source": [
        "### Note\n",
        "1. Congratulations to [@若人生只若初见](https://www.kaggle.com/julianguo)!\n",
        "1. The Notebook: [Fork of Riiid LGBM bagging2.1 471152](https://www.kaggle.com/julianguo/fork-of-riiid-lgbm-bagging2-1-471152) achieved Public Score = 0.783."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "flQ-xuw7azx8",
        "outputId": "db91682b-fd3d-4a27-b891-3461447d43b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ../input/python-datatable/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > /dev/null 2>&1\r\n",
        "\r\n",
        "if COLAB:\r\n",
        "    !pip install datatable"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datatable\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/cb/21810c43b687a19d194c372192049f535fba28c55ce76d37e7e407159c52/datatable-0.11.1-cp36-cp36m-manylinux2010_x86_64.whl (83.7MB)\n",
            "\u001b[K     |████████████████████████████████| 83.7MB 37kB/s \n",
            "\u001b[?25hInstalling collected packages: datatable\n",
            "Successfully installed datatable-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gnHm28QCazx8"
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import datatable as dt\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import psutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "if not COLAB:\n",
        "    import riiideducation\n",
        "\n",
        "_ = np.seterr(divide=\"ignore\", invalid=\"ignore\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8bNtmGcCazx8"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.utils import resample"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tIImh5Tnazx8"
      },
      "source": [
        "## Random seed\n",
        "- This idea is made by [Riiid model LGBM](https://www.kaggle.com/ragnar123/riiid-model-lgbm)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XN9SbRLuazx9"
      },
      "source": [
        "# Initial value\n",
        "SEED = 123\n",
        "\n",
        "# Function to seed everything\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "z_vo1Owlazx9"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "banwXLq9azx9"
      },
      "source": [
        "data_types_dict = {\n",
        "    \"timestamp\": \"int64\",\n",
        "    \"user_id\": \"int32\",\n",
        "    \"content_id\": \"int16\",\n",
        "    \"content_type_id\": \"int8\",\n",
        "    \"task_container_id\": \"int16\",\n",
        "    #'user_answer': 'int8',\n",
        "    \"answered_correctly\": \"int8\",\n",
        "    \"prior_question_elapsed_time\": \"float32\",\n",
        "    \"prior_question_had_explanation\": \"bool\",\n",
        "}\n",
        "target = \"answered_correctly\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6Qf7pCS6azx9"
      },
      "source": [
        "train_df = dt.fread(\n",
        "    f\"{INPUT_ROOT}/train.csv\",\n",
        "    columns=set(data_types_dict.keys()),\n",
        ").to_pandas()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XwvlsvqSazx9",
        "outputId": "2b1b1395-74a2-4c6b-a69d-cde6f07200f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(psutil.virtual_memory().percent)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gal4036aazx9"
      },
      "source": [
        "# reading in lecture df\n",
        "lectures_df = pd.read_csv(f\"{INPUT_ROOT}/lectures.csv\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y3LwSeFWazx-"
      },
      "source": [
        "lectures_df[\"type_of\"] = lectures_df[\"type_of\"].replace(\n",
        "    \"solving question\", \"solving_question\"\n",
        ")\n",
        "lectures_df = pd.get_dummies(lectures_df, columns=[\"part\", \"type_of\"])\n",
        "part_lectures_columns = [\n",
        "    column for column in lectures_df.columns if column.startswith(\"part\")\n",
        "]\n",
        "types_of_lectures_columns = [\n",
        "    column for column in lectures_df.columns if column.startswith(\"type_of_\")\n",
        "]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Eh2IbGSVazx-"
      },
      "source": [
        "train_lectures = train_df[train_df.content_type_id == True].merge(\n",
        "    lectures_df, left_on=\"content_id\", right_on=\"lecture_id\", how=\"left\"\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6HRVfXGDazx-"
      },
      "source": [
        "user_lecture_stats_part = train_lectures.groupby(\"user_id\", as_index=False)[\n",
        "    part_lectures_columns + types_of_lectures_columns\n",
        "].sum()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9em6b5Axazx-"
      },
      "source": [
        "lecturedata_types_dict = {\n",
        "    \"user_id\": \"int32\",\n",
        "    \"part_1\": \"int8\",\n",
        "    \"part_2\": \"int8\",\n",
        "    \"part_3\": \"int8\",\n",
        "    \"part_4\": \"int8\",\n",
        "    \"part_5\": \"int8\",\n",
        "    \"part_6\": \"int8\",\n",
        "    \"part_7\": \"int8\",\n",
        "    \"type_of_concept\": \"int8\",\n",
        "    \"type_of_intention\": \"int8\",\n",
        "    \"type_of_solving_question\": \"int8\",\n",
        "    \"type_of_starter\": \"int8\",\n",
        "}\n",
        "user_lecture_stats_part = user_lecture_stats_part.astype(lecturedata_types_dict)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gJAapJNYazx-"
      },
      "source": [
        "for column in user_lecture_stats_part.columns:\n",
        "    # bool_column = column + '_boolean'\n",
        "    if column != \"user_id\":\n",
        "        user_lecture_stats_part[column] = (user_lecture_stats_part[column] > 0).astype(\n",
        "            \"int8\"\n",
        "        )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iWcUUNiTazx-",
        "outputId": "9091ecf3-0adc-402f-d890-52990557d36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "train_lectures[train_lectures.user_id == 5382]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>content_type_id</th>\n",
              "      <th>task_container_id</th>\n",
              "      <th>answered_correctly</th>\n",
              "      <th>prior_question_elapsed_time</th>\n",
              "      <th>prior_question_had_explanation</th>\n",
              "      <th>lecture_id</th>\n",
              "      <th>tag</th>\n",
              "      <th>part_1</th>\n",
              "      <th>part_2</th>\n",
              "      <th>part_3</th>\n",
              "      <th>part_4</th>\n",
              "      <th>part_5</th>\n",
              "      <th>part_6</th>\n",
              "      <th>part_7</th>\n",
              "      <th>type_of_concept</th>\n",
              "      <th>type_of_intention</th>\n",
              "      <th>type_of_solving_question</th>\n",
              "      <th>type_of_starter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10183847</td>\n",
              "      <td>5382</td>\n",
              "      <td>16736</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>16736</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1424348597</td>\n",
              "      <td>5382</td>\n",
              "      <td>30207</td>\n",
              "      <td>True</td>\n",
              "      <td>104</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>30207</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1425557777</td>\n",
              "      <td>5382</td>\n",
              "      <td>18545</td>\n",
              "      <td>True</td>\n",
              "      <td>121</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>18545</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp  user_id  ...  type_of_solving_question  type_of_starter\n",
              "1    10183847     5382  ...                         0                0\n",
              "2  1424348597     5382  ...                         0                0\n",
              "3  1425557777     5382  ...                         0                0\n",
              "\n",
              "[3 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dhuDcg-lazx_",
        "outputId": "4fe1f57d-92b9-4c35-efef-f85171c70c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "user_lecture_stats_part[user_lecture_stats_part.user_id == 5382]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>part_1</th>\n",
              "      <th>part_2</th>\n",
              "      <th>part_3</th>\n",
              "      <th>part_4</th>\n",
              "      <th>part_5</th>\n",
              "      <th>part_6</th>\n",
              "      <th>part_7</th>\n",
              "      <th>type_of_concept</th>\n",
              "      <th>type_of_intention</th>\n",
              "      <th>type_of_solving_question</th>\n",
              "      <th>type_of_starter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5382</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  part_1  ...  type_of_solving_question  type_of_starter\n",
              "1     5382       1  ...                         0                0\n",
              "\n",
              "[1 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Xkp4kExcazx_",
        "outputId": "a6f322b1-9c58-4df0-f489-419373ec60dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "user_lecture_stats_part.tail()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>part_1</th>\n",
              "      <th>part_2</th>\n",
              "      <th>part_3</th>\n",
              "      <th>part_4</th>\n",
              "      <th>part_5</th>\n",
              "      <th>part_6</th>\n",
              "      <th>part_7</th>\n",
              "      <th>type_of_concept</th>\n",
              "      <th>type_of_intention</th>\n",
              "      <th>type_of_solving_question</th>\n",
              "      <th>type_of_starter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>149601</th>\n",
              "      <td>2147419988</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149602</th>\n",
              "      <td>2147469944</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149603</th>\n",
              "      <td>2147470770</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149604</th>\n",
              "      <td>2147470777</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149605</th>\n",
              "      <td>2147482216</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           user_id  part_1  ...  type_of_solving_question  type_of_starter\n",
              "149601  2147419988       1  ...                         1                0\n",
              "149602  2147469944       1  ...                         0                0\n",
              "149603  2147470770       0  ...                         0                0\n",
              "149604  2147470777       0  ...                         0                0\n",
              "149605  2147482216       0  ...                         0                0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "C6hw1Qa8azx_",
        "outputId": "b6db98b2-cb5a-4546-9f74-0ec303543cb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "user_lecture_stats_part.dtypes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id                     int32\n",
              "part_1                       int8\n",
              "part_2                       int8\n",
              "part_3                       int8\n",
              "part_4                       int8\n",
              "part_5                       int8\n",
              "part_6                       int8\n",
              "part_7                       int8\n",
              "type_of_concept              int8\n",
              "type_of_intention            int8\n",
              "type_of_solving_question     int8\n",
              "type_of_starter              int8\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qCAZWWC5azx_"
      },
      "source": [
        "# clearing memory\n",
        "del train_lectures"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3Nl3LFxQazx_",
        "outputId": "af788186-7a6b-4b1e-f00c-5ff0ae8e17ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(psutil.virtual_memory().percent)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RDpC12IYazx_"
      },
      "source": [
        "cum = train_df.groupby(\"user_id\")[\"content_type_id\"].agg([\"cumsum\", \"cumcount\"])\n",
        "train_df[\"user_lecture_cumsum\"] = cum[\"cumsum\"]\n",
        "train_df[\"user_lecture_lv\"] = cum[\"cumsum\"] / cum[\"cumcount\"]\n",
        "train_df.user_lecture_lv = train_df.user_lecture_lv.astype(\"float16\")\n",
        "train_df.user_lecture_cumsum = train_df.user_lecture_cumsum.astype(\"int8\")\n",
        "user_lecture_agg = train_df.groupby(\"user_id\")[\"content_type_id\"].agg([\"sum\", \"count\"])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4quk4mO0azyA"
      },
      "source": [
        "train_df[\"prior_question_had_explanation\"].fillna(False, inplace=True)\n",
        "train_df = train_df.astype(data_types_dict)\n",
        "train_df = train_df[train_df[target] != -1].reset_index(drop=True)\n",
        "prior_question_elapsed_time_mean = train_df[\"prior_question_elapsed_time\"].mean()\n",
        "train_df[\"prior_question_elapsed_time\"].fillna(\n",
        "    prior_question_elapsed_time_mean, inplace=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mCK7vVn-azyA"
      },
      "source": [
        "max_timestamp_u = (\n",
        "    train_df[[\"user_id\", \"timestamp\"]].groupby([\"user_id\"]).agg([\"max\"]).reset_index()\n",
        ")\n",
        "# max_timestamp_u = train_df[['user_id','timestamp']].groupby(['user_id']).agg(['max'])\n",
        "max_timestamp_u.columns = [\"user_id\", \"max_time_stamp\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WzaFaaWRazyA"
      },
      "source": [
        "train_df[\"lagtime\"] = train_df.groupby(\"user_id\")[\"timestamp\"].shift()\n",
        "train_df[\"lagtime\"] = train_df[\"timestamp\"] - train_df[\"lagtime\"]\n",
        "train_df[\"lagtime\"].fillna(0, inplace=True)\n",
        "train_df.lagtime = train_df.lagtime.astype(\"int32\")\n",
        "# train_df.drop(columns=['timestamp'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "na16pHR3azyA"
      },
      "source": [
        "lagtime_agg = train_df.groupby(\"user_id\")[\"lagtime\"].agg([\"mean\"])\n",
        "train_df[\"lagtime_mean\"] = train_df[\"user_id\"].map(lagtime_agg[\"mean\"])\n",
        "train_df.lagtime_mean = train_df.lagtime_mean.astype(\"int32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "08DWmhgNazyA"
      },
      "source": [
        "user_prior_question_elapsed_time = (\n",
        "    train_df[[\"user_id\", \"prior_question_elapsed_time\"]].groupby([\"user_id\"]).tail(1)\n",
        ")\n",
        "# max_timestamp_u = train_df[['user_id','timestamp']].groupby(['user_id']).agg(['max'])\n",
        "user_prior_question_elapsed_time.columns = [\"user_id\", \"prior_question_elapsed_time\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_CW3fhAXazyA"
      },
      "source": [
        "train_df[\"delta_prior_question_elapsed_time\"] = train_df.groupby(\"user_id\")[\n",
        "    \"prior_question_elapsed_time\"\n",
        "].shift()\n",
        "train_df[\"delta_prior_question_elapsed_time\"] = (\n",
        "    train_df[\"prior_question_elapsed_time\"]\n",
        "    - train_df[\"delta_prior_question_elapsed_time\"]\n",
        ")\n",
        "train_df[\"delta_prior_question_elapsed_time\"].fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m8YpLkyTazyB"
      },
      "source": [
        "train_df.delta_prior_question_elapsed_time = (\n",
        "    train_df.delta_prior_question_elapsed_time.astype(\"int32\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WUxNy04oazyB"
      },
      "source": [
        "train_df[\"timestamp\"] = train_df[\"timestamp\"] / (1000 * 3600)\n",
        "train_df.timestamp = train_df.timestamp.astype(\"int16\")\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tiaJq9FOazyB"
      },
      "source": [
        "train_df[\"lag\"] = train_df.groupby(\"user_id\")[target].shift()\n",
        "\n",
        "cum = train_df.groupby(\"user_id\")[\"lag\"].agg([\"cumsum\", \"cumcount\"])\n",
        "train_df[\"user_correctness\"] = cum[\"cumsum\"] / cum[\"cumcount\"]\n",
        "train_df[\"user_correct_cumsum\"] = cum[\"cumsum\"]\n",
        "train_df[\"user_correct_cumcount\"] = cum[\"cumcount\"]\n",
        "train_df.drop(columns=[\"lag\"], inplace=True)\n",
        "\n",
        "# train_df['user_correctness'].fillna(1, inplace=True)\n",
        "train_df[\"user_correct_cumsum\"].fillna(0, inplace=True)\n",
        "# train_df['user_correct_cumcount'].fillna(0, inplace=True)\n",
        "train_df.user_correctness = train_df.user_correctness.astype(\"float16\")\n",
        "train_df.user_correct_cumcount = train_df.user_correct_cumcount.astype(\"int16\")\n",
        "train_df.user_correct_cumsum = train_df.user_correct_cumsum.astype(\"int16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ppdOhCd9azyC"
      },
      "source": [
        "train_df.prior_question_had_explanation = (\n",
        "    train_df.prior_question_had_explanation.astype(\"int8\")\n",
        ")\n",
        "train_df[\"lag\"] = train_df.groupby(\"user_id\")[\"prior_question_had_explanation\"].shift()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dA_abSSxazyC"
      },
      "source": [
        "cum = train_df.groupby(\"user_id\")[\"lag\"].agg([\"cumsum\", \"cumcount\"])\n",
        "train_df[\"explanation_mean\"] = cum[\"cumsum\"] / cum[\"cumcount\"]\n",
        "train_df[\"explanation_cumsum\"] = cum[\"cumsum\"]\n",
        "train_df.drop(columns=[\"lag\"], inplace=True)\n",
        "train_df[\"explanation_mean\"].fillna(0, inplace=True)\n",
        "train_df[\"explanation_cumsum\"].fillna(0, inplace=True)\n",
        "train_df.explanation_mean = train_df.explanation_mean.astype(\"float16\")\n",
        "train_df.explanation_cumsum = train_df.explanation_cumsum.astype(\"int16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "BaR5OmZNazyC"
      },
      "source": [
        "del cum\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Gp_oKEjWazyC"
      },
      "source": [
        "train_df[\"attempt_no\"] = 1\n",
        "train_df.attempt_no = train_df.attempt_no.astype(\"int8\")\n",
        "train_df[\"attempt_no\"] = (\n",
        "    train_df[[\"user_id\", \"content_id\", \"attempt_no\"]]\n",
        "    .groupby([\"user_id\", \"content_id\"])[\"attempt_no\"]\n",
        "    .cumsum()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PxxzH3r0azyC"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KTLmlufKazyD"
      },
      "source": [
        "train_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s1229h1EazyD"
      },
      "source": [
        "explanation_agg = train_df.groupby(\"user_id\")[\"prior_question_had_explanation\"].agg(\n",
        "    [\"sum\", \"count\"]\n",
        ")\n",
        "explanation_agg = explanation_agg.astype(\"int16\")\n",
        "# train_df.drop(columns=['prior_question_had_explanation'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sWBCL1dAazyD"
      },
      "source": [
        "user_agg = train_df.groupby(\"user_id\")[target].agg([\"sum\", \"count\"])\n",
        "content_agg = train_df.groupby(\"content_id\")[target].agg([\"sum\", \"count\", \"var\"])\n",
        "task_container_agg = train_df.groupby(\"task_container_id\")[target].agg(\n",
        "    [\"sum\", \"count\", \"var\"]\n",
        ")\n",
        "\n",
        "# prior_question_elapsed_time_agg = train_df.groupby('user_id')['prior_question_elapsed_time'].agg(['sum', 'count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "px9kAQXMazyD"
      },
      "source": [
        "user_agg = user_agg.astype(\"int16\")\n",
        "content_agg = content_agg.astype(\"float32\")\n",
        "task_container_agg = task_container_agg.astype(\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8WwxKjTZazyD"
      },
      "source": [
        "attempt_no_agg = train_df.groupby([\"user_id\", \"content_id\"])[\"attempt_no\"].agg([\"sum\"])\n",
        "attempt_no_agg = attempt_no_agg.astype(\"int8\")\n",
        "# attempt_series = train_df[['user_id', 'content_id','attempt_no']].groupby(['user_id','content_id'])['attempt_no'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Do6a1LcjazyD"
      },
      "source": [
        "train_df[\"content_count\"] = (\n",
        "    train_df[\"content_id\"].map(content_agg[\"count\"]).astype(\"int32\")\n",
        ")\n",
        "train_df[\"content_sum\"] = train_df[\"content_id\"].map(content_agg[\"sum\"]).astype(\"int32\")\n",
        "train_df[\"content_correctness\"] = train_df[\"content_id\"].map(\n",
        "    content_agg[\"sum\"] / content_agg[\"count\"]\n",
        ")\n",
        "train_df.content_correctness = train_df.content_correctness.astype(\"float16\")\n",
        "train_df[\"task_container_sum\"] = (\n",
        "    train_df[\"task_container_id\"].map(task_container_agg[\"sum\"]).astype(\"int32\")\n",
        ")\n",
        "train_df[\"task_container_std\"] = (\n",
        "    train_df[\"task_container_id\"].map(task_container_agg[\"var\"]).astype(\"float16\")\n",
        ")\n",
        "train_df[\"task_container_correctness\"] = train_df[\"task_container_id\"].map(\n",
        "    task_container_agg[\"sum\"] / task_container_agg[\"count\"]\n",
        ")\n",
        "train_df.task_container_correctness = train_df.task_container_correctness.astype(\n",
        "    \"float16\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dZy210T8azyE"
      },
      "source": [
        "questions_df = pd.read_csv(\n",
        "    f\"{INPUT_ROOT}/questions.csv\",\n",
        "    usecols=[0, 1, 3, 4],\n",
        "    dtype={\"question_id\": \"int16\", \"bundle_id\": \"int16\", \"part\": \"int8\", \"tags\": \"str\"},\n",
        ")\n",
        "questions_df[\"part_bundle_id\"] = (\n",
        "    questions_df[\"part\"] * 100000 + questions_df[\"bundle_id\"]\n",
        ")\n",
        "questions_df.part_bundle_id = questions_df.part_bundle_id.astype(\"int32\")\n",
        "tag = questions_df[\"tags\"].str.split(\" \", n=10, expand=True)\n",
        "tag.columns = [\"tags1\", \"tags2\", \"tags3\", \"tags4\", \"tags5\", \"tags6\"]\n",
        "#\n",
        "\n",
        "tag.fillna(0, inplace=True)\n",
        "tag = tag.astype(\"int16\")\n",
        "questions_df = pd.concat([questions_df, tag], axis=1).drop([\"tags\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "641UpGOyazyE"
      },
      "source": [
        "questions_df.rename(columns={\"question_id\": \"content_id\"}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZvZR8RmMazyE"
      },
      "source": [
        "questions_df[\"content_correctness\"] = questions_df[\"content_id\"].map(\n",
        "    content_agg[\"sum\"] / content_agg[\"count\"]\n",
        ")\n",
        "questions_df.content_correctness = questions_df.content_correctness.astype(\"float16\")\n",
        "questions_df[\"content_correctness_std\"] = questions_df[\"content_id\"].map(\n",
        "    content_agg[\"var\"]\n",
        ")\n",
        "questions_df.content_correctness_std = questions_df.content_correctness_std.astype(\n",
        "    \"float16\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9PTaigTQazyE"
      },
      "source": [
        "part_agg = questions_df.groupby(\"part\")[\"content_correctness\"].agg([\"mean\", \"var\"])\n",
        "questions_df[\"part_correctness_mean\"] = questions_df[\"part\"].map(part_agg[\"mean\"])\n",
        "questions_df[\"part_correctness_std\"] = questions_df[\"part\"].map(part_agg[\"var\"])\n",
        "questions_df.part_correctness_mean = questions_df.part_correctness_mean.astype(\n",
        "    \"float16\"\n",
        ")\n",
        "questions_df.part_correctness_std = questions_df.part_correctness_std.astype(\"float16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bSyecmgMazyE"
      },
      "source": [
        "bundle_agg = questions_df.groupby(\"bundle_id\")[\"content_correctness\"].agg([\"mean\"])\n",
        "questions_df[\"bundle_correctness\"] = questions_df[\"bundle_id\"].map(bundle_agg[\"mean\"])\n",
        "questions_df.bundle_correctness = questions_df.bundle_correctness.astype(\"float16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aB3kC18XazyE"
      },
      "source": [
        "tags1_agg = questions_df.groupby(\"tags1\")[\"content_correctness\"].agg([\"mean\", \"var\"])\n",
        "questions_df[\"tags1_correctness_mean\"] = questions_df[\"tags1\"].map(tags1_agg[\"mean\"])\n",
        "questions_df[\"tags1_correctness_std\"] = questions_df[\"tags1\"].map(tags1_agg[\"var\"])\n",
        "questions_df.tags1_correctness_mean = questions_df.tags1_correctness_mean.astype(\n",
        "    \"float16\"\n",
        ")\n",
        "questions_df.tags1_correctness_std = questions_df.tags1_correctness_std.astype(\n",
        "    \"float16\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yb6xBnLwazyE"
      },
      "source": [
        "questions_df.drop(columns=[\"content_correctness\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "evwn5fJ6azyF"
      },
      "source": [
        "questions_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "M5l2pT6lazyF"
      },
      "source": [
        "del bundle_agg\n",
        "del part_agg\n",
        "del tags1_agg\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "f8Ie-OT3azyF"
      },
      "source": [
        "# pd.set_option(\"display.max_columns\",500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y136Q906azyF"
      },
      "source": [
        "# questions_df.drop(columns=['tags4','tags5','tags6'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wKEGHyI9azyF"
      },
      "source": [
        "len(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "13dKDgjLazyF"
      },
      "source": [
        "train_df[\"user_correctness\"].fillna(1, inplace=True)\n",
        "train_df[\"attempt_no\"].fillna(1, inplace=True)\n",
        "#\n",
        "train_df.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lKCWbafGazyF",
        "outputId": "0231af4f-69f8-498b-b5c3-2e700a8c7a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-193753be380d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hl3bn3cHazyG"
      },
      "source": [
        "train_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rISQTi3DazyG"
      },
      "source": [
        "# SAKT Part I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PT003pryazyG"
      },
      "source": [
        "# HDKIM\n",
        "\n",
        "# this is the max lenght of the sequence of the sakt model.\n",
        "MAX_SEQ = 160\n",
        "\n",
        "skills = train_df[\"content_id\"].unique()\n",
        "n_skill = len(skills)\n",
        "print(\"number skills\", len(skills))\n",
        "\n",
        "group = (\n",
        "    train_df[[\"user_id\", \"content_id\", \"answered_correctly\"]]\n",
        "    .groupby(\"user_id\")\n",
        "    .apply(lambda r: (r[\"content_id\"].values, r[\"answered_correctly\"].values))\n",
        ")\n",
        "\n",
        "for user_id in group.index:\n",
        "    q, qa = group[user_id]\n",
        "    if len(q) > MAX_SEQ:\n",
        "        group[user_id] = (q[-MAX_SEQ:], qa[-MAX_SEQ:])\n",
        "\n",
        "pickle.dump(group, open(\"group.pkl\", \"wb\"))\n",
        "del group\n",
        "gc.collect()\n",
        "\n",
        "# HDKIMHDKIM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "XzZbE67mazyG"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-KBlx6gKazyG"
      },
      "source": [
        "features = [\n",
        "    #   'user_id',\n",
        "    # HDKIM    'timestamp',\n",
        "    \"lagtime\",\n",
        "    \"lagtime_mean\",\n",
        "    # 'content_id',\n",
        "    # 'task_container_id',\n",
        "    \"user_lecture_cumsum\",  # X\n",
        "    \"user_lecture_lv\",\n",
        "    \"prior_question_elapsed_time\",\n",
        "    \"delta_prior_question_elapsed_time\",\n",
        "    \"user_correctness\",\n",
        "    \"user_correct_cumcount\",  # X\n",
        "    \"user_correct_cumsum\",  # X\n",
        "    \"content_correctness\",\n",
        "    # 'content_correctness_std',\n",
        "    \"content_count\",\n",
        "    \"content_sum\",  # X\n",
        "    \"task_container_correctness\",\n",
        "    # 'task_container_std',\n",
        "    # 'task_container_sum',\n",
        "    \"bundle_correctness\",\n",
        "    \"attempt_no\",\n",
        "    \"part\",\n",
        "    \"part_correctness_mean\",\n",
        "    # 'part_correctness_std',\n",
        "    \"tags1\",\n",
        "    \"tags1_correctness_mean\",\n",
        "    #  'tags1_correctness_std',\n",
        "    # HDKIM    'tags2',\n",
        "    # HDKIM    'tags3',\n",
        "    # HDKIM    'tags4',\n",
        "    # HDKIM    'tags5',\n",
        "    # HDKIM    'tags6',\n",
        "    \"bundle_id\",\n",
        "    #  'part_bundle_id',\n",
        "    \"explanation_mean\",\n",
        "    \"explanation_cumsum\",\n",
        "    \"prior_question_had_explanation\",\n",
        "    #     'part_1',\n",
        "    #     'part_2',\n",
        "    #     'part_3',\n",
        "    #     'part_4',\n",
        "    #     'part_5',\n",
        "    #     'part_6',\n",
        "    #     'part_7',\n",
        "    #     'type_of_concept',\n",
        "    #     'type_of_intention',\n",
        "    #     'type_of_solving_question',\n",
        "    #     'type_of_starter'\n",
        "]\n",
        "categorical_columns = [\n",
        "    #   'user_id',\n",
        "    #  'content_id',\n",
        "    # 'task_container_id',\n",
        "    \"part\",\n",
        "    \"tags1\",\n",
        "    # HDKIM    'tags2',\n",
        "    # HDKIM    'tags3',\n",
        "    # HDKIM    'tags4',\n",
        "    # HDKIM    'tags5',\n",
        "    # HDKIM    'tags6',\n",
        "    \"bundle_id\",\n",
        "    # 'part_bundle_id',\n",
        "    \"prior_question_had_explanation\",\n",
        "    #     'part_1',\n",
        "    #     'part_2',\n",
        "    #     'part_3',\n",
        "    #     'part_4',\n",
        "    #     'part_5',\n",
        "    #     'part_6',\n",
        "    #     'part_7',\n",
        "    #     'type_of_concept',\n",
        "    #     'type_of_intention',\n",
        "    #     'type_of_solving_question',\n",
        "    #     'type_of_starter'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EEF7eAO5azyG"
      },
      "source": [
        "flag_lgbm = True\n",
        "clfs = list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ruXzcXKRazyG"
      },
      "source": [
        "## Load the parameters with Optuna from [this Notebook](https://github.com/satorushibata0627/Publishment/blob/main/Kaggle_Python3_LightGBM_on_GPU_with_Feature_Engineering_Optuna_and_Visualization.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "el8oAIxZazyG"
      },
      "source": [
        "params = pd.read_pickle(\n",
        "    \"../input/the-best-of-all-parameters-on-lightgbm/The_best_of_all_parameters_on_LightGBM.pickle\"\n",
        ")\n",
        "print(\"Optimized parameters with Optuna:\")\n",
        "print(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DnD9Wy1IazyH"
      },
      "source": [
        "trains = list()\n",
        "valids = list()\n",
        "num = 1\n",
        "for i in range(0, num):\n",
        "\n",
        "    train_df_clf = train_df.sample(n=20000 * 1000, random_state=SEED)\n",
        "    print(\"sample end\")\n",
        "\n",
        "    del train_df\n",
        "\n",
        "    users = train_df_clf[\"user_id\"].drop_duplicates()\n",
        "\n",
        "    users = users.sample(frac=0.025, random_state=SEED)\n",
        "    users_df = pd.DataFrame()\n",
        "    users_df[\"user_id\"] = users.values\n",
        "\n",
        "    valid_df_newuser = pd.merge(\n",
        "        train_df_clf, users_df, on=[\"user_id\"], how=\"inner\", right_index=True\n",
        "    )\n",
        "    del users_df\n",
        "    del users\n",
        "    gc.collect()\n",
        "    #\n",
        "    train_df_clf.drop(valid_df_newuser.index, inplace=True)\n",
        "\n",
        "    train_df_clf = pd.merge(\n",
        "        train_df_clf, questions_df, on=\"content_id\", how=\"left\", right_index=True\n",
        "    )  #\n",
        "    valid_df_newuser = pd.merge(\n",
        "        valid_df_newuser, questions_df, on=\"content_id\", how=\"left\", right_index=True\n",
        "    )  #\n",
        "\n",
        "    valid_df = train_df_clf.sample(frac=0.09, random_state=SEED)\n",
        "    train_df_clf.drop(valid_df.index, inplace=True)\n",
        "\n",
        "    valid_df = valid_df.append(valid_df_newuser)\n",
        "    del valid_df_newuser\n",
        "    gc.collect()\n",
        "    #\n",
        "\n",
        "    trains.append(train_df_clf)\n",
        "    valids.append(valid_df)\n",
        "    print(\"valid_df lengthÃ¯Â¼Å¡\", len(valid_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Agv4AopxazyH"
      },
      "source": [
        "del train_df_clf\n",
        "del valid_df\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "t1houHGGazyH"
      },
      "source": [
        "### Refer to [Riiid model LGBM](https://www.kaggle.com/ragnar123/riiid-model-lgbm/notebook) for following:\n",
        "- num_boost_round\n",
        "- early_stopping_rounds\n",
        "- verbose_eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WZFzTxMBazyH"
      },
      "source": [
        "for i in range(0, num):\n",
        "\n",
        "    #\n",
        "    tr_data = lgb.Dataset(trains[i][features], label=trains[i][target])\n",
        "    va_data = lgb.Dataset(\n",
        "        valids[i][features], label=valids[i][target], reference=tr_data\n",
        "    )\n",
        "\n",
        "    #     del train_df_clf\n",
        "    #     del valid_df\n",
        "    #     gc.collect()\n",
        "    del trains\n",
        "    del valids\n",
        "    gc.collect()\n",
        "\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        tr_data,\n",
        "        #         train_df[features],\n",
        "        #         train_df[target],\n",
        "        num_boost_round=10000,\n",
        "        # valid_sets=[(train_df[features],train_df[target]), (valid_df[features],valid_df[target])],\n",
        "        valid_sets=[tr_data, va_data],\n",
        "        early_stopping_rounds=50,\n",
        "        feature_name=features,\n",
        "        categorical_feature=categorical_columns,\n",
        "        verbose_eval=50,\n",
        "    )\n",
        "    clfs.append(model)\n",
        "\n",
        "    # Clean the memory\n",
        "    del tr_data\n",
        "    del va_data\n",
        "    gc.collect()\n",
        "#\n",
        "# del trains\n",
        "# del valids\n",
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kfwtWg1XazyH"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x5hOdx2mazyH"
      },
      "source": [
        "user_sum_dict = user_agg[\"sum\"].astype(\"int16\").to_dict(defaultdict(int))\n",
        "user_count_dict = user_agg[\"count\"].astype(\"int16\").to_dict(defaultdict(int))\n",
        "content_sum_dict = content_agg[\"sum\"].astype(\"int32\").to_dict(defaultdict(int))\n",
        "content_count_dict = content_agg[\"count\"].astype(\"int32\").to_dict(defaultdict(int))\n",
        "\n",
        "del user_agg\n",
        "del content_agg\n",
        "gc.collect()\n",
        "\n",
        "task_container_sum_dict = (\n",
        "    task_container_agg[\"sum\"].astype(\"int32\").to_dict(defaultdict(int))\n",
        ")\n",
        "task_container_count_dict = (\n",
        "    task_container_agg[\"count\"].astype(\"int32\").to_dict(defaultdict(int))\n",
        ")\n",
        "task_container_std_dict = (\n",
        "    task_container_agg[\"var\"].astype(\"float16\").to_dict(defaultdict(int))\n",
        ")\n",
        "\n",
        "explanation_sum_dict = explanation_agg[\"sum\"].astype(\"int16\").to_dict(defaultdict(int))\n",
        "explanation_count_dict = (\n",
        "    explanation_agg[\"count\"].astype(\"int16\").to_dict(defaultdict(int))\n",
        ")\n",
        "del task_container_agg\n",
        "del explanation_agg\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "shJ-nv6EazyH"
      },
      "source": [
        "user_lecture_sum_dict = (\n",
        "    user_lecture_agg[\"sum\"].astype(\"int16\").to_dict(defaultdict(int))\n",
        ")\n",
        "user_lecture_count_dict = (\n",
        "    user_lecture_agg[\"count\"].astype(\"int16\").to_dict(defaultdict(int))\n",
        ")\n",
        "\n",
        "lagtime_mean_dict = lagtime_agg[\"mean\"].astype(\"int32\").to_dict(defaultdict(int))\n",
        "# del prior_question_elapsed_time_agg\n",
        "del user_lecture_agg\n",
        "del lagtime_agg\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Wa43TTRsazyI"
      },
      "source": [
        "attempt_no_agg = attempt_no_agg[attempt_no_agg[\"sum\"] > 1]\n",
        "attempt_no_sum_dict = attempt_no_agg[\"sum\"].to_dict(defaultdict(int))\n",
        "\n",
        "del attempt_no_agg\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c_gXLjsiazyI"
      },
      "source": [
        "max_timestamp_u_dict = max_timestamp_u.set_index(\"user_id\").to_dict()\n",
        "user_prior_question_elapsed_time_dict = user_prior_question_elapsed_time.set_index(\n",
        "    \"user_id\"\n",
        ").to_dict()\n",
        "# del question_elapsed_time_agg\n",
        "del max_timestamp_u\n",
        "del user_prior_question_elapsed_time\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EpVyItfYazyI"
      },
      "source": [
        "len(max_timestamp_u_dict[\"max_time_stamp\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yvhAGsXKazyI"
      },
      "source": [
        "def get_max_attempt(user_id, content_id):\n",
        "    k = (user_id, content_id)\n",
        "\n",
        "    if k in attempt_no_sum_dict.keys():\n",
        "        attempt_no_sum_dict[k] += 1\n",
        "        return attempt_no_sum_dict[k]\n",
        "\n",
        "    attempt_no_sum_dict[k] = 1\n",
        "    return attempt_no_sum_dict[k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sdECy9zCazyI"
      },
      "source": [
        "print(psutil.virtual_memory().percent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "l1fyQHuyazyI"
      },
      "source": [
        "# SAKT Part II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "atxLckxgazyI"
      },
      "source": [
        "# HDKIM SAKT\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, state_size=200):\n",
        "        super(FFN, self).__init__()\n",
        "        self.state_size = state_size\n",
        "\n",
        "        self.lr1 = nn.Linear(state_size, state_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lr2 = nn.Linear(state_size, state_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lr1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lr2(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "def future_mask(seq_length):\n",
        "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype(\"bool\")\n",
        "    return torch.from_numpy(future_mask)\n",
        "\n",
        "\n",
        "class SAKTModel(nn.Module):\n",
        "    def __init__(self, n_skill, max_seq=MAX_SEQ, embed_dim=128):  # HDKIM 100\n",
        "        super(SAKTModel, self).__init__()\n",
        "        self.n_skill = n_skill\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(2 * n_skill + 1, embed_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_seq - 1, embed_dim)\n",
        "        self.e_embedding = nn.Embedding(n_skill + 1, embed_dim)\n",
        "\n",
        "        self.multi_att = nn.MultiheadAttention(\n",
        "            embed_dim=embed_dim, num_heads=8, dropout=0.2\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.layer_normal = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.ffn = FFN(embed_dim)\n",
        "        self.pred = nn.Linear(embed_dim, 1)\n",
        "\n",
        "    def forward(self, x, question_ids):\n",
        "        device = x.device\n",
        "        x = self.embedding(x)\n",
        "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
        "\n",
        "        pos_x = self.pos_embedding(pos_id)\n",
        "        x = x + pos_x\n",
        "\n",
        "        e = self.e_embedding(question_ids)\n",
        "\n",
        "        x = x.permute(1, 0, 2)  # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
        "        e = e.permute(1, 0, 2)\n",
        "        att_mask = future_mask(x.size(0)).to(device)\n",
        "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
        "        att_output = self.layer_normal(att_output + e)\n",
        "        att_output = att_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
        "\n",
        "        x = self.ffn(att_output)\n",
        "        x = self.layer_normal(x + att_output)\n",
        "        x = self.pred(x)\n",
        "\n",
        "        return x.squeeze(-1), att_weight\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, samples, test_df, skills, max_seq=MAX_SEQ):  # HDKIM 100\n",
        "        super(TestDataset, self).__init__()\n",
        "        self.samples = samples\n",
        "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
        "        self.test_df = test_df\n",
        "        self.skills = skills\n",
        "        self.n_skill = len(skills)\n",
        "        self.max_seq = max_seq\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.test_df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        test_info = self.test_df.iloc[index]\n",
        "\n",
        "        user_id = test_info[\"user_id\"]\n",
        "        target_id = test_info[\"content_id\"]\n",
        "\n",
        "        q = np.zeros(self.max_seq, dtype=int)\n",
        "        qa = np.zeros(self.max_seq, dtype=int)\n",
        "\n",
        "        if user_id in self.samples.index:\n",
        "            q_, qa_ = self.samples[user_id]\n",
        "\n",
        "            seq_len = len(q_)\n",
        "\n",
        "            if seq_len >= self.max_seq:\n",
        "                q = q_[-self.max_seq :]\n",
        "                qa = qa_[-self.max_seq :]\n",
        "            else:\n",
        "                q[-seq_len:] = q_\n",
        "                qa[-seq_len:] = qa_\n",
        "\n",
        "        x = np.zeros(self.max_seq - 1, dtype=int)\n",
        "        x = q[1:].copy()\n",
        "        x += (qa[1:] == 1) * self.n_skill\n",
        "\n",
        "        questions = np.append(q[2:], [target_id])\n",
        "\n",
        "        return x, questions\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SAKT_model = SAKTModel(n_skill, embed_dim=128)\n",
        "\n",
        "try:\n",
        "    SAKT_model.load_state_dict(\n",
        "        torch.load(\"../input/sakt-with-randomization-state-updates/SAKT-HDKIM.pt\")\n",
        "    )\n",
        "except:\n",
        "    SAKT_model.load_state_dict(\n",
        "        torch.load(\n",
        "            \"../input/sakt-with-randomization-state-updates/SAKT-HDKIM.pt\",\n",
        "            map_location=\"cpu\",\n",
        "        )\n",
        "    )\n",
        "\n",
        "SAKT_model.to(device)\n",
        "SAKT_model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DShJkzZ7azyJ"
      },
      "source": [
        "group = pickle.load(open(\"group.pkl\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rFwoleD1azyJ"
      },
      "source": [
        "print(psutil.virtual_memory().percent)\n",
        "# HDKIMHDKIM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "XhgryaBxazyJ"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rHRDXxn5azyJ"
      },
      "source": [
        "env = riiideducation.make_env()\n",
        "iter_test = env.iter_test()\n",
        "prior_test_df = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-IEd2A80azyJ"
      },
      "source": [
        "%%time\n",
        "\n",
        "for (test_df, sample_prediction_df) in iter_test:\n",
        "    if (prior_test_df is not None) & (psutil.virtual_memory().percent < 90):\n",
        "        print(psutil.virtual_memory().percent)\n",
        "        prior_test_df[target] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
        "        prior_test_df = prior_test_df[prior_test_df[target] != -1].reset_index(\n",
        "            drop=True\n",
        "        )\n",
        "        prior_test_df[\"prior_question_had_explanation\"].fillna(False, inplace=True)\n",
        "        prior_test_df.prior_question_had_explanation = (\n",
        "            prior_test_df.prior_question_had_explanation.astype(\"int8\")\n",
        "        )\n",
        "\n",
        "        # HDKIM SAKT State Update\n",
        "        prev_group = (\n",
        "            prior_test_df[[\"user_id\", \"content_id\", \"answered_correctly\"]]\n",
        "            .groupby(\"user_id\")\n",
        "            .apply(lambda r: (r[\"content_id\"].values, r[\"answered_correctly\"].values))\n",
        "        )\n",
        "        for prev_user_id in prev_group.index:\n",
        "            prev_group_content = prev_group[prev_user_id][0]\n",
        "            prev_group_ac = prev_group[prev_user_id][1]\n",
        "            if prev_user_id in group.index:\n",
        "                group[prev_user_id] = (\n",
        "                    np.append(group[prev_user_id][0], prev_group_content),\n",
        "                    np.append(group[prev_user_id][1], prev_group_ac),\n",
        "                )\n",
        "            else:\n",
        "                group[prev_user_id] = (prev_group_content, prev_group_ac)\n",
        "            if len(group[prev_user_id][0]) > MAX_SEQ:\n",
        "                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n",
        "                new_group_ac = group[prev_user_id][1][-MAX_SEQ:]\n",
        "                group[prev_user_id] = (new_group_content, new_group_ac)\n",
        "\n",
        "        # HDKIMHDKIM\n",
        "\n",
        "        user_ids = prior_test_df[\"user_id\"].values\n",
        "        content_ids = prior_test_df[\"content_id\"].values\n",
        "        task_container_ids = prior_test_df[\"task_container_id\"].values\n",
        "        prior_question_had_explanations = prior_test_df[\n",
        "            \"prior_question_had_explanation\"\n",
        "        ].values\n",
        "        targets = prior_test_df[target].values\n",
        "\n",
        "        for (\n",
        "            user_id,\n",
        "            content_id,\n",
        "            prior_question_had_explanation,\n",
        "            task_container_id,\n",
        "            answered_correctly,\n",
        "        ) in zip(\n",
        "            user_ids,\n",
        "            content_ids,\n",
        "            prior_question_had_explanations,\n",
        "            task_container_ids,\n",
        "            targets,\n",
        "        ):\n",
        "            user_sum_dict[user_id] += answered_correctly\n",
        "            user_count_dict[user_id] += 1\n",
        "            explanation_sum_dict[user_id] += prior_question_had_explanation\n",
        "            explanation_count_dict[user_id] += 1\n",
        "\n",
        "    prior_test_df = test_df.copy()\n",
        "    lecture_test_df = test_df[test_df[\"content_type_id\"] == 1].reset_index(drop=True)\n",
        "\n",
        "    for i, (user_id, content_type_id, content_id) in enumerate(\n",
        "        zip(\n",
        "            lecture_test_df[\"user_id\"].values,\n",
        "            lecture_test_df[\"content_type_id\"].values,\n",
        "            lecture_test_df[\"content_id\"].values,\n",
        "        )\n",
        "    ):\n",
        "\n",
        "        user_lecture_sum_dict[user_id] += content_type_id\n",
        "        user_lecture_count_dict[user_id] += 1\n",
        "        #\n",
        "        if (\n",
        "            len(user_lecture_stats_part[user_lecture_stats_part.user_id == user_id])\n",
        "            == 0\n",
        "        ):\n",
        "            user_lecture_stats_part = user_lecture_stats_part.append(\n",
        "                [{\"user_id\": user_id}], ignore_index=True\n",
        "            )\n",
        "            user_lecture_stats_part.fillna(0, inplace=True)\n",
        "            user_lecture_stats_part.loc[\n",
        "                user_lecture_stats_part.user_id == user_id,\n",
        "                part_lectures_columns + types_of_lectures_columns,\n",
        "            ] += lectures_df[lectures_df.lecture_id == content_id][\n",
        "                part_lectures_columns + types_of_lectures_columns\n",
        "            ].values\n",
        "        else:\n",
        "            user_lecture_stats_part.loc[\n",
        "                user_lecture_stats_part.user_id == user_id,\n",
        "                part_lectures_columns + types_of_lectures_columns,\n",
        "            ] += lectures_df[lectures_df.lecture_id == content_id][\n",
        "                part_lectures_columns + types_of_lectures_columns\n",
        "            ].values\n",
        "\n",
        "    test_df = test_df[test_df[\"content_type_id\"] == 0].reset_index(drop=True)\n",
        "\n",
        "    # HDKIM SAKT\n",
        "    test_dataset = TestDataset(group, test_df, skills)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=51200, shuffle=False)\n",
        "\n",
        "    SAKT_outs = []\n",
        "\n",
        "    for item in test_dataloader:\n",
        "        x = item[0].to(device).long()\n",
        "        target_id = item[1].to(device).long()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, att_weight = SAKT_model(x, target_id)\n",
        "\n",
        "        output = torch.sigmoid(output)\n",
        "        output = output[:, -1]\n",
        "        SAKT_outs.extend(output.view(-1).data.cpu().numpy())\n",
        "\n",
        "    # HDKIMHDKIM\n",
        "\n",
        "    test_df[\"prior_question_had_explanation\"].fillna(False, inplace=True)\n",
        "    test_df.prior_question_had_explanation = (\n",
        "        test_df.prior_question_had_explanation.astype(\"int8\")\n",
        "    )\n",
        "    test_df[\"prior_question_elapsed_time\"].fillna(\n",
        "        prior_question_elapsed_time_mean, inplace=True\n",
        "    )\n",
        "\n",
        "    user_lecture_sum = np.zeros(len(test_df), dtype=np.int16)\n",
        "    user_lecture_count = np.zeros(len(test_df), dtype=np.int16)\n",
        "\n",
        "    user_sum = np.zeros(len(test_df), dtype=np.int16)\n",
        "    user_count = np.zeros(len(test_df), dtype=np.int16)\n",
        "    content_sum = np.zeros(len(test_df), dtype=np.int32)\n",
        "    content_count = np.zeros(len(test_df), dtype=np.int32)\n",
        "    task_container_sum = np.zeros(len(test_df), dtype=np.int32)\n",
        "    task_container_count = np.zeros(len(test_df), dtype=np.int32)\n",
        "    task_container_std = np.zeros(len(test_df), dtype=np.float16)\n",
        "    content_task_mean = np.zeros(len(test_df), dtype=np.float16)\n",
        "    explanation_sum = np.zeros(len(test_df), dtype=np.int32)\n",
        "    explanation_count = np.zeros(len(test_df), dtype=np.int32)\n",
        "    delta_prior_question_elapsed_time = np.zeros(len(test_df), dtype=np.int32)\n",
        "\n",
        "    attempt_no_count = np.zeros(len(test_df), dtype=np.int16)\n",
        "    lagtime = np.zeros(len(test_df), dtype=np.int32)\n",
        "    lagtime_mean = np.zeros(len(test_df), dtype=np.int32)\n",
        "\n",
        "    for i, (\n",
        "        user_id,\n",
        "        prior_question_had_explanation,\n",
        "        content_type_id,\n",
        "        prior_question_elapsed_time,\n",
        "        timestamp,\n",
        "        content_id,\n",
        "        task_container_id,\n",
        "    ) in enumerate(\n",
        "        zip(\n",
        "            test_df[\"user_id\"].values,\n",
        "            test_df[\"prior_question_had_explanation\"].values,\n",
        "            test_df[\"content_type_id\"].values,\n",
        "            test_df[\"prior_question_elapsed_time\"].values,\n",
        "            test_df[\"timestamp\"].values,\n",
        "            test_df[\"content_id\"].values,\n",
        "            test_df[\"task_container_id\"].values,\n",
        "        )\n",
        "    ):\n",
        "\n",
        "        user_lecture_sum_dict[user_id] += content_type_id\n",
        "        user_lecture_count_dict[user_id] += 1\n",
        "\n",
        "        user_lecture_sum[i] = user_lecture_sum_dict[user_id]\n",
        "        user_lecture_count[i] = user_lecture_count_dict[user_id]\n",
        "\n",
        "        user_sum[i] = user_sum_dict[user_id]\n",
        "        user_count[i] = user_count_dict[user_id]\n",
        "        content_sum[i] = content_sum_dict[content_id]\n",
        "        content_count[i] = content_count_dict[content_id]\n",
        "        task_container_sum[i] = task_container_sum_dict[task_container_id]\n",
        "        task_container_count[i] = task_container_count_dict[task_container_id]\n",
        "        task_container_std[i] = task_container_std_dict[task_container_id]\n",
        "\n",
        "        explanation_sum[i] = explanation_sum_dict[user_id]\n",
        "        explanation_count[i] = explanation_count_dict[user_id]\n",
        "\n",
        "        if user_id in max_timestamp_u_dict[\"max_time_stamp\"].keys():\n",
        "            lagtime[i] = timestamp - max_timestamp_u_dict[\"max_time_stamp\"][user_id]\n",
        "            max_timestamp_u_dict[\"max_time_stamp\"][user_id] = timestamp\n",
        "            lagtime_mean[i] = (lagtime_mean_dict[user_id] + lagtime[i]) / 2\n",
        "        else:\n",
        "            lagtime[i] = 0\n",
        "            max_timestamp_u_dict[\"max_time_stamp\"].update({user_id: timestamp})\n",
        "            lagtime_mean_dict.update({user_id: timestamp})\n",
        "            lagtime_mean[i] = (lagtime_mean_dict[user_id] + lagtime[i]) / 2\n",
        "\n",
        "        if (\n",
        "            user_id\n",
        "            in user_prior_question_elapsed_time_dict[\n",
        "                \"prior_question_elapsed_time\"\n",
        "            ].keys()\n",
        "        ):\n",
        "            delta_prior_question_elapsed_time[i] = (\n",
        "                prior_question_elapsed_time\n",
        "                - user_prior_question_elapsed_time_dict[\"prior_question_elapsed_time\"][\n",
        "                    user_id\n",
        "                ]\n",
        "            )\n",
        "            user_prior_question_elapsed_time_dict[\"prior_question_elapsed_time\"][\n",
        "                user_id\n",
        "            ] = prior_question_elapsed_time\n",
        "        else:\n",
        "            delta_prior_question_elapsed_time[i] = 0\n",
        "            user_prior_question_elapsed_time_dict[\"prior_question_elapsed_time\"].update(\n",
        "                {user_id: prior_question_elapsed_time}\n",
        "            )\n",
        "\n",
        "    #\n",
        "    # test_df = pd.merge(test_df, questions_df, on='content_id', how='left',right_index=True)\n",
        "    # test_df = pd.concat([test_df.reset_index(drop=True), questions_df.reindex(test_df['content_id'].values).reset_index(drop=True)], axis=1)\n",
        "    test_df = test_df.merge(\n",
        "        questions_df.loc[questions_df.index.isin(test_df[\"content_id\"])],\n",
        "        how=\"left\",\n",
        "        on=\"content_id\",\n",
        "        right_index=True,\n",
        "    )\n",
        "\n",
        "    # test_df = pd.merge(test_df, user_lecture_stats_part, on=['user_id'], how=\"left\",right_index=True)\n",
        "    # test_df = pd.concat([test_df.reset_index(drop=True), user_lecture_stats_part.reindex(test_df['user_id'].values).reset_index(drop=True)], axis=1)\n",
        "    #     test_df=test_df.merge(user_lecture_stats_part.loc[user_lecture_stats_part.index.isin(test_df['user_id'])],\n",
        "    #                   how='left', on='user_id', right_index=True)\n",
        "\n",
        "    test_df[\"user_lecture_lv\"] = user_lecture_sum / user_lecture_count\n",
        "    test_df[\"user_lecture_cumsum\"] = user_lecture_sum\n",
        "    test_df[\"user_correctness\"] = user_sum / user_count\n",
        "    test_df[\"user_correct_cumcount\"] = user_count\n",
        "    test_df[\"user_correct_cumsum\"] = user_sum\n",
        "    #\n",
        "    test_df[\"content_correctness\"] = content_sum / content_count\n",
        "    test_df[\"content_count\"] = content_count\n",
        "    test_df[\"content_sum\"] = content_sum\n",
        "\n",
        "    test_df[\"task_container_correctness\"] = task_container_sum / task_container_count\n",
        "    test_df[\"task_container_sum\"] = task_container_sum\n",
        "    test_df[\"task_container_std\"] = task_container_std\n",
        "    # test_df['content_task_mean'] = content_task_mean\n",
        "\n",
        "    test_df[\"explanation_mean\"] = explanation_sum / explanation_count\n",
        "    test_df[\"explanation_cumsum\"] = explanation_sum\n",
        "\n",
        "    #\n",
        "    test_df[\"delta_prior_question_elapsed_time\"] = delta_prior_question_elapsed_time\n",
        "\n",
        "    test_df[\"attempt_no\"] = test_df[[\"user_id\", \"content_id\"]].apply(\n",
        "        lambda row: get_max_attempt(row[\"user_id\"], row[\"content_id\"]), axis=1\n",
        "    )\n",
        "    test_df[\"lagtime\"] = lagtime\n",
        "    test_df[\"lagtime_mean\"] = lagtime_mean\n",
        "\n",
        "    test_df[\"user_correctness\"].fillna(1, inplace=True)\n",
        "    test_df[\"attempt_no\"].fillna(1, inplace=True)\n",
        "    #\n",
        "    test_df.fillna(0, inplace=True)\n",
        "\n",
        "    test_df[\"timestamp\"] = test_df[\"timestamp\"] / (1000 * 3600)\n",
        "    test_df.timestamp = test_df.timestamp.astype(\"int16\")\n",
        "\n",
        "    sub_preds = np.zeros(test_df.shape[0])\n",
        "\n",
        "    for i, model in enumerate(clfs, 1):\n",
        "        test_preds = model.predict(\n",
        "            test_df[features], num_iteration=model.best_iteration\n",
        "        )\n",
        "        sub_preds += test_preds\n",
        "\n",
        "    # HDKIM\n",
        "    # test_df[target] = sub_preds / len(clfs) #HDKIM\n",
        "\n",
        "    lgbm_final = sub_preds / len(clfs)\n",
        "    test_df[target] = np.array(SAKT_outs) * 0.5 + lgbm_final * 0.5\n",
        "    # HDKIMHDKIM\n",
        "\n",
        "    # Submission\n",
        "    env.predict(test_df[[\"row_id\", target]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "G4aEaaO7azyJ"
      },
      "source": [
        "## Save files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iFveV-nUazyJ"
      },
      "source": [
        "# test_df\n",
        "pickle.dump(test_df, open(\"test_df.pickle\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lzTmCbkYazyK"
      },
      "source": [
        "# Model\n",
        "model.save_model(\"model.txt\")\n",
        "print(\"Save the best of model.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JHk2hRWHazyK"
      },
      "source": [
        "# Parameters\n",
        "pickle.dump(params, open(\"The_best_of_all_parameters_on_LightGBM.pickle\", \"wb\"))\n",
        "print(\"Save the best of parameters.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "GiYGI37LazyK"
      },
      "source": [
        "# Visualization & Empirical analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "unGWYaT5azyK"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ef2KdrU3azyK"
      },
      "source": [
        "target = \"answered_correctly\"\n",
        "y_true = pd.read_csv(\n",
        "    \"../input/riiid-test-answer-prediction/train.csv\", usecols=[target]\n",
        ")\n",
        "print(\"Length of y_true =\", len(y_true))\n",
        "y_pred = pd.read_csv(\"./submission.csv\", usecols=[target])\n",
        "print(\"Length of y_pred =\", len(y_pred))\n",
        "test_df = pd.read_pickle(\"./test_df.pickle\")\n",
        "print(\"Length of test_df =\", len(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pPucwf1lazyK"
      },
      "source": [
        "params = pd.read_pickle(\"./The_best_of_all_parameters_on_LightGBM.pickle\")\n",
        "print(\"Optimized parameters with Optuna:\")\n",
        "print(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZtAlh4aTazyK"
      },
      "source": [
        "model = lgb.Booster(model_file=\"./model.txt\", params=params)\n",
        "print(\"Load the model of LightGBM:\")\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LPietFJwazyK"
      },
      "source": [
        "features = model.feature_name()\n",
        "print(\"Features of LightGBM:\")\n",
        "print(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jhusoicwazyL"
      },
      "source": [
        "LightGBM = model.predict(test_df[features])\n",
        "LightGBM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AcORlAoDazyL"
      },
      "source": [
        "# Run bootstrap\n",
        "y_true_boot = resample(y_true, n_samples=len(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-aSj2q0LazyL"
      },
      "source": [
        "## Define functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CY_zcgKEazyL"
      },
      "source": [
        "def Plot_lgb(model):\n",
        "    plt.figure()\n",
        "    lgb.plot_importance(model, importance_type=\"gain\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    lgb.plot_tree(model, figsize=(30, 50))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hqf7zdC5azyL"
      },
      "source": [
        "def Statistical_Significance_Test(y_true_boot, y_pred):\n",
        "    A = np.array(y_true_boot)\n",
        "    B = np.array(y_pred)\n",
        "    # Paired t-test\n",
        "    print(\"Paired t-test:\", stats.ttest_rel(A, B))\n",
        "    # Student's t-test\n",
        "    A_var = np.var(A, ddof=1)  # Unbiased dispersion of A\n",
        "    B_var = np.var(B, ddof=1)  # Unbiased dispersion of B\n",
        "    A_df = len(A) - 1  # Degree of freedom of A\n",
        "    B_df = len(B) - 1  # Degree of freedom of B\n",
        "    f = A_var / B_var  # F ratio value\n",
        "    one_sided_pval1 = stats.f.cdf(f, A_df, B_df)  # One-sided test p-value(1)\n",
        "    one_sided_pval2 = stats.f.sf(f, A_df, B_df)  # One-sided test p-value(2)\n",
        "    two_sided_pval = min(one_sided_pval1, one_sided_pval2) * 2  # Two-sided test p-value\n",
        "    print(\"Student's t-test:\")\n",
        "    print(\"F:       \", round(f, 3))\n",
        "    print(\"p-value: \", round(two_sided_pval, 3))\n",
        "    # Welch's t-test\n",
        "    two_sided_pval = min(one_sided_pval1, one_sided_pval2) * 2  # Two-sided test p-value\n",
        "    print(\"Welch's t-test:\")\n",
        "    print(\"F:       \", round(f, 3))\n",
        "    print(\"p-value: \", round(two_sided_pval, 4))\n",
        "    # Mann-Whitney's U-test\n",
        "    print(\"Mann-Whitney's U-test:\", stats.mannwhitneyu(A, B, alternative=\"two-sided\"))\n",
        "    # Wilcoxon signed rank sum test\n",
        "    print(\"Wilcoxon signed rank sum test:\", stats.wilcoxon(A, B))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hv0RMugyazyL"
      },
      "source": [
        "# Histogram\n",
        "def distribution(df):\n",
        "    plt.figure()\n",
        "    sns.distplot(\n",
        "        df,\n",
        "        kde=True,\n",
        "        rug=True,\n",
        "        hist=True,\n",
        "        norm_hist=True,\n",
        "        axlabel=\"Frequency Distribution\",\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "n44neV_cazyM"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-BWHXuKAazyM"
      },
      "source": [
        "Plot_lgb(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VvYaQEIHazyM"
      },
      "source": [
        "Statistical_Significance_Test(y_true_boot[target], y_pred[target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "VEzU-5mWazyM"
      },
      "source": [
        "### Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "a8CYDnJnazyM"
      },
      "source": [
        "distribution(y_true_boot[target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5Ea5iV7iazyM"
      },
      "source": [
        "distribution(y_pred[target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cp4F69MWazyM"
      },
      "source": [
        "distribution(LightGBM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3rLgtEnOazyM"
      },
      "source": [
        "### Done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ApcWzLYZazyN"
      },
      "source": [
        "print(\"Operation completed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "D80HL83UazyN"
      },
      "source": [
        "## I would like to thank the original author, [@Ammar Alhaj Ali](https://www.kaggle.com/ammarnassanalhajali) deeply."
      ]
    }
  ]
}